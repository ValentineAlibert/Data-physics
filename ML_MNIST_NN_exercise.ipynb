{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_MNIST_NN_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentineAlibert/Data-physics/blob/master/ML_MNIST_NN_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XpGNAvNbSzkK",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8IRtFU1ZWO0a",
        "colab": {}
      },
      "source": [
        "# load training and test images (x), and their respective classified labels (y).\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5G5KLASFWlnX",
        "outputId": "ff0570f0-9e1d-4bfb-d604-778a96e82f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Investigate the data\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mping\n",
        "\n",
        "print(\"Training data shape: \", x_train.shape) # (60000, 28, 28) -- 60000 images, each 28x28 pixels\n",
        "print(\"Test data shape\", x_test.shape) # (10000, 28, 28) -- 10000 images, each 28x28\n",
        "print(\"First 10 training labels as digits:\\n\", y_train[:10])\n",
        "print(\"\")\n",
        "\n",
        "# Plot the first 10 images\n",
        "\n",
        "\n",
        "w = 10 #width\n",
        "h = 10 #height\n",
        "fig = plt.figure(figsize=(h, w))  \n",
        "columns = 5 \n",
        "rows = 2\n",
        "j = 0 # setting variable for iteration over numbers\n",
        "\n",
        "for i in range(1, columns*rows +1): #+1 \n",
        "    img = np.random.randint(10, size=(h,w)) #new image \n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(x_train[j]) \n",
        "    j = j+1 #go through data \"numbers\" - with images\n",
        "\n",
        "plt.show()\n",
        "\n",
        "### --> Find a way to plot a sample of 10 images of hand-written digits in the training data\n",
        "### END STUDENT CODE ###"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape:  (60000, 28, 28)\n",
            "Test data shape (10000, 28, 28)\n",
            "First 10 training labels as digits:\n",
            " [5 0 4 1 9 2 1 3 1 4]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAGqCAYAAADEA3qnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUAAAAIEooAAAAAJRQAEAAAT6/4W6/ajuMom1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nk6I1PweS7Br",
        "outputId": "19d8bc34-b2b6-42d1-b051-b9e227ea817d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# Pre-processing of data\n",
        "\n",
        "# Flatten the images\n",
        "image_vector_size = 28*28\n",
        "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
        "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
        "print(\"reshaped training data format: \", x_train.shape) # -- 60000 images, now flat arrays of 28*28 long\n",
        "\n",
        "# one-hot encode the labels\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(\"First 10 training lables as one-hot encoded vectors:\\n\", y_train[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reshaped training data format:  (60000, 784)\n",
            "First 10 training lables as one-hot encoded vectors:\n",
            " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f8HyorlxTUgO",
        "outputId": "b4481a8d-7a9e-4ebc-be9a-84f35ee8fc9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# Build the network\n",
        "from keras.layers import Dense # Dense layers are \"fully connected\" layers\n",
        "from keras.models import Sequential # Documentation: https://keras.io/models/sequential/\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(65,activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# The input layer requires the special input_shape parameter, which should equal the shape of our training data.\n",
        "# The output layer must be the same size as the (one-hot encoded) labels.\n",
        "# Choose a non-linear activation function such as a sigmoid, or relu.\n",
        "# For classification purposes, where the outputs are normalized 'probabilities' between the classes,\n",
        "#  one typically uses the softmax activation function for the last layer.\n",
        "\n",
        "### STUDENT CODE HERE ###\n",
        "### --> add Dense (fully connected) layers to the model to connect input to output.\n",
        "###  Make sure that the dimensionality is correct: input should be # pixels large, \n",
        "###  output should be #classes large. Google is your friend.\n",
        "### END STUDENT CODE ###\n",
        "\n",
        "# Print model summary. Shows network layout, and # free parameters (weights + biases) to adapt while learning.\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 65)                51025     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                660       \n",
            "=================================================================\n",
            "Total params: 51,685\n",
            "Trainable params: 51,685\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xLA4UyhnTjUK",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "# A good loss function for probability classification that works well with softmax is the 'categorical crossentropy'.\n",
        "#  It's a function of the difference between the predicted y (from running the image through the network),\n",
        "#  and the actual label y that we get from the dataset. The larger the loss, the worst our network is performing.\n",
        "# A good optimizer is the stochastic gradient descent (sgd) or adam.\n",
        "\n",
        "### STUDENT CODE HERE ###\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
        "\n",
        "### --> Call model.compile with the right arguments.\n",
        "### END STUDENT CODE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXK3rjE1fBr",
        "colab_type": "text"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hpxjqt02r4bJ",
        "outputId": "d2a58b9a-deff-4be1-fc8c-9aaa732f813e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Let's see how good the model 'predicts' some hand-written digits in our test dataset, without training.\n",
        "# It's probably random: so for 10 digits, it should get an accuracy around 0.1 .\n",
        "\n",
        "loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "print(f'Test loss: {loss:.3}')\n",
        "print(f'Test accuracy: {accuracy:.3}')\n",
        "\n",
        "### STUDENT CODE HERE ###\n",
        "model.predict_proba(x_train)\n",
        "### --> call model.predict_proba() on the test images, and show the predictions of the\n",
        "###  untrained model for the first 10 images. Also, plot those images, as you did above.\n",
        "### END STUDENT CODE ###\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.84\n",
            "Test accuracy: 0.121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09824143, 0.02083364, 0.15171011, ..., 0.3639296 , 0.00595385,\n",
              "        0.135595  ],\n",
              "       [0.13993326, 0.03170397, 0.10471863, ..., 0.06841765, 0.00895923,\n",
              "        0.13971196],\n",
              "       [0.09984408, 0.05520745, 0.12408692, ..., 0.3209779 , 0.01743547,\n",
              "        0.14879125],\n",
              "       ...,\n",
              "       [0.08765382, 0.0458182 , 0.0892097 , ..., 0.33139148, 0.01821724,\n",
              "        0.2456214 ],\n",
              "       [0.10352389, 0.02007703, 0.03954683, ..., 0.02439176, 0.01307277,\n",
              "        0.07107545],\n",
              "       [0.06375705, 0.02520508, 0.124909  , ..., 0.07583275, 0.00393716,\n",
              "        0.16015323]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gCkCK2BZZRG5",
        "outputId": "93d31654-de73-4f3b-ad6a-1b55486bce8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model.\n",
        "\n",
        "# BATCH_SIZE defines how many images to process at once.\n",
        "# EPOCHS defines how often to run over the total data (60000 images)\n",
        "# (Note that a small part of the train data is internally split off for independent validation of the metrics)\n",
        "\n",
        "### STUDENT CODE HERE ###\n",
        "### --> Edit the parameters below to obtain a better accuracy in the training.\n",
        "\n",
        "BATCH_SIZE = 10000\n",
        "EPOCHS = 100\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_split=.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/1000\n",
            "54000/54000 [==============================] - 1s 13us/step - loss: 2.7167 - acc: 0.1289 - val_loss: 2.5182 - val_acc: 0.1537\n",
            "Epoch 2/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 2.4181 - acc: 0.1761 - val_loss: 2.2768 - val_acc: 0.2068\n",
            "Epoch 3/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 2.2146 - acc: 0.2306 - val_loss: 2.1149 - val_acc: 0.2630\n",
            "Epoch 4/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 2.0746 - acc: 0.2880 - val_loss: 1.9973 - val_acc: 0.3257\n",
            "Epoch 5/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.9703 - acc: 0.3395 - val_loss: 1.9031 - val_acc: 0.3743\n",
            "Epoch 6/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.8865 - acc: 0.3818 - val_loss: 1.8256 - val_acc: 0.4148\n",
            "Epoch 7/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 1.8145 - acc: 0.4189 - val_loss: 1.7570 - val_acc: 0.4505\n",
            "Epoch 8/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.7504 - acc: 0.4538 - val_loss: 1.6955 - val_acc: 0.4812\n",
            "Epoch 9/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.6946 - acc: 0.4826 - val_loss: 1.6399 - val_acc: 0.5128\n",
            "Epoch 10/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.6426 - acc: 0.5109 - val_loss: 1.5896 - val_acc: 0.5333\n",
            "Epoch 11/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.5954 - acc: 0.5357 - val_loss: 1.5448 - val_acc: 0.5548\n",
            "Epoch 12/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.5520 - acc: 0.5574 - val_loss: 1.5040 - val_acc: 0.5745\n",
            "Epoch 13/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.5126 - acc: 0.5760 - val_loss: 1.4643 - val_acc: 0.5927\n",
            "Epoch 14/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.4762 - acc: 0.5926 - val_loss: 1.4293 - val_acc: 0.6057\n",
            "Epoch 15/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.4426 - acc: 0.6078 - val_loss: 1.3952 - val_acc: 0.6267\n",
            "Epoch 16/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.4118 - acc: 0.6234 - val_loss: 1.3658 - val_acc: 0.6415\n",
            "Epoch 17/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.3834 - acc: 0.6362 - val_loss: 1.3369 - val_acc: 0.6568\n",
            "Epoch 18/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.3565 - acc: 0.6484 - val_loss: 1.3103 - val_acc: 0.6665\n",
            "Epoch 19/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.3306 - acc: 0.6611 - val_loss: 1.2840 - val_acc: 0.6775\n",
            "Epoch 20/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.3061 - acc: 0.6699 - val_loss: 1.2582 - val_acc: 0.6907\n",
            "Epoch 21/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.2826 - acc: 0.6814 - val_loss: 1.2335 - val_acc: 0.7002\n",
            "Epoch 22/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.2597 - acc: 0.6910 - val_loss: 1.2100 - val_acc: 0.7135\n",
            "Epoch 23/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 1.2379 - acc: 0.7001 - val_loss: 1.1880 - val_acc: 0.7245\n",
            "Epoch 24/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 1.2172 - acc: 0.7099 - val_loss: 1.1655 - val_acc: 0.7380\n",
            "Epoch 25/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.1977 - acc: 0.7185 - val_loss: 1.1463 - val_acc: 0.7487\n",
            "Epoch 26/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.1788 - acc: 0.7265 - val_loss: 1.1271 - val_acc: 0.7560\n",
            "Epoch 27/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.1610 - acc: 0.7324 - val_loss: 1.1079 - val_acc: 0.7635\n",
            "Epoch 28/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.1434 - acc: 0.7370 - val_loss: 1.0904 - val_acc: 0.7715\n",
            "Epoch 29/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 1.1264 - acc: 0.7452 - val_loss: 1.0729 - val_acc: 0.7738\n",
            "Epoch 30/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 1.1098 - acc: 0.7499 - val_loss: 1.0556 - val_acc: 0.7807\n",
            "Epoch 31/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 1.0935 - acc: 0.7561 - val_loss: 1.0397 - val_acc: 0.7862\n",
            "Epoch 32/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 1.0780 - acc: 0.7613 - val_loss: 1.0239 - val_acc: 0.7910\n",
            "Epoch 33/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.0630 - acc: 0.7656 - val_loss: 1.0087 - val_acc: 0.7973\n",
            "Epoch 34/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.0486 - acc: 0.7708 - val_loss: 0.9942 - val_acc: 0.8047\n",
            "Epoch 35/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.0350 - acc: 0.7747 - val_loss: 0.9799 - val_acc: 0.8085\n",
            "Epoch 36/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.0217 - acc: 0.7785 - val_loss: 0.9661 - val_acc: 0.8138\n",
            "Epoch 37/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 1.0090 - acc: 0.7823 - val_loss: 0.9533 - val_acc: 0.8183\n",
            "Epoch 38/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.9968 - acc: 0.7862 - val_loss: 0.9411 - val_acc: 0.8208\n",
            "Epoch 39/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.9853 - acc: 0.7890 - val_loss: 0.9292 - val_acc: 0.8232\n",
            "Epoch 40/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.9743 - acc: 0.7924 - val_loss: 0.9183 - val_acc: 0.8272\n",
            "Epoch 41/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.9638 - acc: 0.7952 - val_loss: 0.9073 - val_acc: 0.8277\n",
            "Epoch 42/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.9534 - acc: 0.7980 - val_loss: 0.8971 - val_acc: 0.8310\n",
            "Epoch 43/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.9432 - acc: 0.8012 - val_loss: 0.8872 - val_acc: 0.8323\n",
            "Epoch 44/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.9335 - acc: 0.8039 - val_loss: 0.8773 - val_acc: 0.8345\n",
            "Epoch 45/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.9243 - acc: 0.8059 - val_loss: 0.8679 - val_acc: 0.8368\n",
            "Epoch 46/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.9151 - acc: 0.8083 - val_loss: 0.8577 - val_acc: 0.8400\n",
            "Epoch 47/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.9064 - acc: 0.8099 - val_loss: 0.8486 - val_acc: 0.8412\n",
            "Epoch 48/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8976 - acc: 0.8126 - val_loss: 0.8395 - val_acc: 0.8435\n",
            "Epoch 49/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.8890 - acc: 0.8142 - val_loss: 0.8307 - val_acc: 0.8447\n",
            "Epoch 50/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.8808 - acc: 0.8159 - val_loss: 0.8220 - val_acc: 0.8480\n",
            "Epoch 51/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8728 - acc: 0.8177 - val_loss: 0.8142 - val_acc: 0.8490\n",
            "Epoch 52/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8653 - acc: 0.8189 - val_loss: 0.8071 - val_acc: 0.8495\n",
            "Epoch 53/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8578 - acc: 0.8212 - val_loss: 0.7987 - val_acc: 0.8502\n",
            "Epoch 54/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8504 - acc: 0.8225 - val_loss: 0.7915 - val_acc: 0.8523\n",
            "Epoch 55/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.8432 - acc: 0.8245 - val_loss: 0.7841 - val_acc: 0.8547\n",
            "Epoch 56/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.8363 - acc: 0.8255 - val_loss: 0.7777 - val_acc: 0.8558\n",
            "Epoch 57/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8297 - acc: 0.8274 - val_loss: 0.7707 - val_acc: 0.8565\n",
            "Epoch 58/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8233 - acc: 0.8281 - val_loss: 0.7643 - val_acc: 0.8587\n",
            "Epoch 59/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8169 - acc: 0.8296 - val_loss: 0.7580 - val_acc: 0.8605\n",
            "Epoch 60/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.8108 - acc: 0.8309 - val_loss: 0.7518 - val_acc: 0.8613\n",
            "Epoch 61/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.8048 - acc: 0.8320 - val_loss: 0.7455 - val_acc: 0.8620\n",
            "Epoch 62/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.7990 - acc: 0.8336 - val_loss: 0.7399 - val_acc: 0.8652\n",
            "Epoch 63/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7931 - acc: 0.8340 - val_loss: 0.7344 - val_acc: 0.8643\n",
            "Epoch 64/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7874 - acc: 0.8352 - val_loss: 0.7286 - val_acc: 0.8670\n",
            "Epoch 65/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7819 - acc: 0.8366 - val_loss: 0.7237 - val_acc: 0.8660\n",
            "Epoch 66/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7763 - acc: 0.8378 - val_loss: 0.7177 - val_acc: 0.8678\n",
            "Epoch 67/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.7710 - acc: 0.8395 - val_loss: 0.7129 - val_acc: 0.8675\n",
            "Epoch 68/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7656 - acc: 0.8406 - val_loss: 0.7077 - val_acc: 0.8690\n",
            "Epoch 69/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7605 - acc: 0.8416 - val_loss: 0.7035 - val_acc: 0.8685\n",
            "Epoch 70/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7554 - acc: 0.8422 - val_loss: 0.6991 - val_acc: 0.8702\n",
            "Epoch 71/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7506 - acc: 0.8432 - val_loss: 0.6938 - val_acc: 0.8698\n",
            "Epoch 72/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7459 - acc: 0.8442 - val_loss: 0.6893 - val_acc: 0.8693\n",
            "Epoch 73/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7412 - acc: 0.8454 - val_loss: 0.6845 - val_acc: 0.8708\n",
            "Epoch 74/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.7366 - acc: 0.8466 - val_loss: 0.6801 - val_acc: 0.8720\n",
            "Epoch 75/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7322 - acc: 0.8473 - val_loss: 0.6757 - val_acc: 0.8735\n",
            "Epoch 76/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7278 - acc: 0.8478 - val_loss: 0.6714 - val_acc: 0.8748\n",
            "Epoch 77/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7234 - acc: 0.8491 - val_loss: 0.6674 - val_acc: 0.8750\n",
            "Epoch 78/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7192 - acc: 0.8496 - val_loss: 0.6633 - val_acc: 0.8748\n",
            "Epoch 79/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7151 - acc: 0.8505 - val_loss: 0.6592 - val_acc: 0.8758\n",
            "Epoch 80/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7110 - acc: 0.8516 - val_loss: 0.6552 - val_acc: 0.8762\n",
            "Epoch 81/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.7071 - acc: 0.8524 - val_loss: 0.6513 - val_acc: 0.8778\n",
            "Epoch 82/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.7032 - acc: 0.8533 - val_loss: 0.6478 - val_acc: 0.8758\n",
            "Epoch 83/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6993 - acc: 0.8539 - val_loss: 0.6442 - val_acc: 0.8778\n",
            "Epoch 84/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6956 - acc: 0.8550 - val_loss: 0.6403 - val_acc: 0.8777\n",
            "Epoch 85/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6918 - acc: 0.8557 - val_loss: 0.6365 - val_acc: 0.8797\n",
            "Epoch 86/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6882 - acc: 0.8563 - val_loss: 0.6331 - val_acc: 0.8790\n",
            "Epoch 87/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6846 - acc: 0.8570 - val_loss: 0.6293 - val_acc: 0.8798\n",
            "Epoch 88/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6811 - acc: 0.8577 - val_loss: 0.6262 - val_acc: 0.8798\n",
            "Epoch 89/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6777 - acc: 0.8582 - val_loss: 0.6226 - val_acc: 0.8807\n",
            "Epoch 90/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6743 - acc: 0.8588 - val_loss: 0.6195 - val_acc: 0.8812\n",
            "Epoch 91/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6709 - acc: 0.8594 - val_loss: 0.6161 - val_acc: 0.8827\n",
            "Epoch 92/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6677 - acc: 0.8598 - val_loss: 0.6130 - val_acc: 0.8832\n",
            "Epoch 93/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6645 - acc: 0.8606 - val_loss: 0.6103 - val_acc: 0.8828\n",
            "Epoch 94/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6614 - acc: 0.8615 - val_loss: 0.6072 - val_acc: 0.8833\n",
            "Epoch 95/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6582 - acc: 0.8617 - val_loss: 0.6042 - val_acc: 0.8837\n",
            "Epoch 96/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6552 - acc: 0.8621 - val_loss: 0.6020 - val_acc: 0.8835\n",
            "Epoch 97/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6521 - acc: 0.8627 - val_loss: 0.5990 - val_acc: 0.8845\n",
            "Epoch 98/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6492 - acc: 0.8630 - val_loss: 0.5958 - val_acc: 0.8833\n",
            "Epoch 99/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6463 - acc: 0.8636 - val_loss: 0.5933 - val_acc: 0.8845\n",
            "Epoch 100/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6432 - acc: 0.8639 - val_loss: 0.5907 - val_acc: 0.8842\n",
            "Epoch 101/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6403 - acc: 0.8645 - val_loss: 0.5880 - val_acc: 0.8843\n",
            "Epoch 102/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6374 - acc: 0.8649 - val_loss: 0.5854 - val_acc: 0.8852\n",
            "Epoch 103/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6346 - acc: 0.8648 - val_loss: 0.5823 - val_acc: 0.8867\n",
            "Epoch 104/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6318 - acc: 0.8656 - val_loss: 0.5798 - val_acc: 0.8868\n",
            "Epoch 105/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6289 - acc: 0.8660 - val_loss: 0.5772 - val_acc: 0.8868\n",
            "Epoch 106/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6264 - acc: 0.8664 - val_loss: 0.5745 - val_acc: 0.8867\n",
            "Epoch 107/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6236 - acc: 0.8670 - val_loss: 0.5720 - val_acc: 0.8877\n",
            "Epoch 108/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6209 - acc: 0.8672 - val_loss: 0.5694 - val_acc: 0.8875\n",
            "Epoch 109/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6183 - acc: 0.8675 - val_loss: 0.5670 - val_acc: 0.8873\n",
            "Epoch 110/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6157 - acc: 0.8683 - val_loss: 0.5646 - val_acc: 0.8873\n",
            "Epoch 111/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6131 - acc: 0.8688 - val_loss: 0.5623 - val_acc: 0.8888\n",
            "Epoch 112/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6107 - acc: 0.8690 - val_loss: 0.5594 - val_acc: 0.8875\n",
            "Epoch 113/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6082 - acc: 0.8694 - val_loss: 0.5574 - val_acc: 0.8883\n",
            "Epoch 114/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.6059 - acc: 0.8696 - val_loss: 0.5550 - val_acc: 0.8895\n",
            "Epoch 115/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6034 - acc: 0.8702 - val_loss: 0.5528 - val_acc: 0.8893\n",
            "Epoch 116/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.6011 - acc: 0.8704 - val_loss: 0.5504 - val_acc: 0.8895\n",
            "Epoch 117/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5987 - acc: 0.8709 - val_loss: 0.5482 - val_acc: 0.8900\n",
            "Epoch 118/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5964 - acc: 0.8714 - val_loss: 0.5458 - val_acc: 0.8907\n",
            "Epoch 119/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5942 - acc: 0.8718 - val_loss: 0.5435 - val_acc: 0.8917\n",
            "Epoch 120/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5919 - acc: 0.8727 - val_loss: 0.5415 - val_acc: 0.8915\n",
            "Epoch 121/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5897 - acc: 0.8727 - val_loss: 0.5397 - val_acc: 0.8923\n",
            "Epoch 122/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5875 - acc: 0.8730 - val_loss: 0.5377 - val_acc: 0.8927\n",
            "Epoch 123/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5853 - acc: 0.8735 - val_loss: 0.5352 - val_acc: 0.8935\n",
            "Epoch 124/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5830 - acc: 0.8738 - val_loss: 0.5336 - val_acc: 0.8937\n",
            "Epoch 125/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5811 - acc: 0.8743 - val_loss: 0.5321 - val_acc: 0.8940\n",
            "Epoch 126/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5789 - acc: 0.8746 - val_loss: 0.5299 - val_acc: 0.8930\n",
            "Epoch 127/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5769 - acc: 0.8753 - val_loss: 0.5284 - val_acc: 0.8930\n",
            "Epoch 128/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5749 - acc: 0.8755 - val_loss: 0.5264 - val_acc: 0.8943\n",
            "Epoch 129/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5727 - acc: 0.8760 - val_loss: 0.5250 - val_acc: 0.8938\n",
            "Epoch 130/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5708 - acc: 0.8761 - val_loss: 0.5232 - val_acc: 0.8950\n",
            "Epoch 131/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5689 - acc: 0.8764 - val_loss: 0.5215 - val_acc: 0.8945\n",
            "Epoch 132/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5670 - acc: 0.8766 - val_loss: 0.5195 - val_acc: 0.8952\n",
            "Epoch 133/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5651 - acc: 0.8769 - val_loss: 0.5181 - val_acc: 0.8953\n",
            "Epoch 134/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5632 - acc: 0.8775 - val_loss: 0.5160 - val_acc: 0.8955\n",
            "Epoch 135/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5614 - acc: 0.8780 - val_loss: 0.5142 - val_acc: 0.8945\n",
            "Epoch 136/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5596 - acc: 0.8781 - val_loss: 0.5131 - val_acc: 0.8947\n",
            "Epoch 137/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5577 - acc: 0.8782 - val_loss: 0.5117 - val_acc: 0.8947\n",
            "Epoch 138/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5560 - acc: 0.8787 - val_loss: 0.5096 - val_acc: 0.8962\n",
            "Epoch 139/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5542 - acc: 0.8787 - val_loss: 0.5078 - val_acc: 0.8958\n",
            "Epoch 140/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5523 - acc: 0.8790 - val_loss: 0.5062 - val_acc: 0.8960\n",
            "Epoch 141/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5506 - acc: 0.8793 - val_loss: 0.5046 - val_acc: 0.8960\n",
            "Epoch 142/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5490 - acc: 0.8799 - val_loss: 0.5030 - val_acc: 0.8967\n",
            "Epoch 143/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5472 - acc: 0.8802 - val_loss: 0.5015 - val_acc: 0.8955\n",
            "Epoch 144/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5455 - acc: 0.8805 - val_loss: 0.5003 - val_acc: 0.8960\n",
            "Epoch 145/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5440 - acc: 0.8803 - val_loss: 0.4983 - val_acc: 0.8962\n",
            "Epoch 146/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5423 - acc: 0.8805 - val_loss: 0.4966 - val_acc: 0.8952\n",
            "Epoch 147/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5407 - acc: 0.8813 - val_loss: 0.4956 - val_acc: 0.8953\n",
            "Epoch 148/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5390 - acc: 0.8816 - val_loss: 0.4937 - val_acc: 0.8963\n",
            "Epoch 149/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5376 - acc: 0.8818 - val_loss: 0.4929 - val_acc: 0.8965\n",
            "Epoch 150/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5359 - acc: 0.8821 - val_loss: 0.4913 - val_acc: 0.8968\n",
            "Epoch 151/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5344 - acc: 0.8821 - val_loss: 0.4894 - val_acc: 0.8957\n",
            "Epoch 152/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5328 - acc: 0.8826 - val_loss: 0.4882 - val_acc: 0.8972\n",
            "Epoch 153/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5313 - acc: 0.8831 - val_loss: 0.4871 - val_acc: 0.8962\n",
            "Epoch 154/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5297 - acc: 0.8836 - val_loss: 0.4860 - val_acc: 0.8967\n",
            "Epoch 155/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5283 - acc: 0.8834 - val_loss: 0.4840 - val_acc: 0.8978\n",
            "Epoch 156/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5267 - acc: 0.8838 - val_loss: 0.4831 - val_acc: 0.8970\n",
            "Epoch 157/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5253 - acc: 0.8841 - val_loss: 0.4819 - val_acc: 0.8975\n",
            "Epoch 158/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5238 - acc: 0.8845 - val_loss: 0.4803 - val_acc: 0.8975\n",
            "Epoch 159/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5223 - acc: 0.8843 - val_loss: 0.4789 - val_acc: 0.8988\n",
            "Epoch 160/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5209 - acc: 0.8846 - val_loss: 0.4781 - val_acc: 0.8987\n",
            "Epoch 161/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5195 - acc: 0.8848 - val_loss: 0.4770 - val_acc: 0.8982\n",
            "Epoch 162/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5181 - acc: 0.8849 - val_loss: 0.4756 - val_acc: 0.8990\n",
            "Epoch 163/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5166 - acc: 0.8852 - val_loss: 0.4742 - val_acc: 0.8987\n",
            "Epoch 164/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5153 - acc: 0.8855 - val_loss: 0.4728 - val_acc: 0.8988\n",
            "Epoch 165/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5141 - acc: 0.8856 - val_loss: 0.4719 - val_acc: 0.8997\n",
            "Epoch 166/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5126 - acc: 0.8859 - val_loss: 0.4711 - val_acc: 0.8995\n",
            "Epoch 167/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5112 - acc: 0.8860 - val_loss: 0.4694 - val_acc: 0.9000\n",
            "Epoch 168/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5099 - acc: 0.8865 - val_loss: 0.4680 - val_acc: 0.8995\n",
            "Epoch 169/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.5086 - acc: 0.8865 - val_loss: 0.4668 - val_acc: 0.8990\n",
            "Epoch 170/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5074 - acc: 0.8865 - val_loss: 0.4657 - val_acc: 0.8997\n",
            "Epoch 171/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5060 - acc: 0.8867 - val_loss: 0.4644 - val_acc: 0.9005\n",
            "Epoch 172/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5048 - acc: 0.8870 - val_loss: 0.4635 - val_acc: 0.9012\n",
            "Epoch 173/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5035 - acc: 0.8872 - val_loss: 0.4625 - val_acc: 0.9007\n",
            "Epoch 174/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5023 - acc: 0.8873 - val_loss: 0.4617 - val_acc: 0.9012\n",
            "Epoch 175/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.5011 - acc: 0.8876 - val_loss: 0.4601 - val_acc: 0.9003\n",
            "Epoch 176/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4998 - acc: 0.8880 - val_loss: 0.4591 - val_acc: 0.9003\n",
            "Epoch 177/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4986 - acc: 0.8881 - val_loss: 0.4576 - val_acc: 0.9015\n",
            "Epoch 178/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4975 - acc: 0.8881 - val_loss: 0.4572 - val_acc: 0.9018\n",
            "Epoch 179/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4962 - acc: 0.8883 - val_loss: 0.4565 - val_acc: 0.9023\n",
            "Epoch 180/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4951 - acc: 0.8887 - val_loss: 0.4551 - val_acc: 0.9017\n",
            "Epoch 181/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4939 - acc: 0.8890 - val_loss: 0.4540 - val_acc: 0.9025\n",
            "Epoch 182/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4928 - acc: 0.8894 - val_loss: 0.4530 - val_acc: 0.9018\n",
            "Epoch 183/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4916 - acc: 0.8894 - val_loss: 0.4517 - val_acc: 0.9033\n",
            "Epoch 184/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4906 - acc: 0.8895 - val_loss: 0.4509 - val_acc: 0.9022\n",
            "Epoch 185/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4895 - acc: 0.8895 - val_loss: 0.4500 - val_acc: 0.9022\n",
            "Epoch 186/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4884 - acc: 0.8896 - val_loss: 0.4492 - val_acc: 0.9032\n",
            "Epoch 187/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4871 - acc: 0.8899 - val_loss: 0.4480 - val_acc: 0.9028\n",
            "Epoch 188/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4861 - acc: 0.8900 - val_loss: 0.4472 - val_acc: 0.9033\n",
            "Epoch 189/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4851 - acc: 0.8903 - val_loss: 0.4463 - val_acc: 0.9035\n",
            "Epoch 190/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4840 - acc: 0.8901 - val_loss: 0.4453 - val_acc: 0.9032\n",
            "Epoch 191/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4828 - acc: 0.8906 - val_loss: 0.4443 - val_acc: 0.9042\n",
            "Epoch 192/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4816 - acc: 0.8902 - val_loss: 0.4435 - val_acc: 0.9040\n",
            "Epoch 193/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4807 - acc: 0.8904 - val_loss: 0.4426 - val_acc: 0.9040\n",
            "Epoch 194/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4797 - acc: 0.8908 - val_loss: 0.4417 - val_acc: 0.9042\n",
            "Epoch 195/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4787 - acc: 0.8908 - val_loss: 0.4409 - val_acc: 0.9040\n",
            "Epoch 196/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4775 - acc: 0.8912 - val_loss: 0.4401 - val_acc: 0.9038\n",
            "Epoch 197/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4763 - acc: 0.8914 - val_loss: 0.4389 - val_acc: 0.9045\n",
            "Epoch 198/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4754 - acc: 0.8918 - val_loss: 0.4383 - val_acc: 0.9042\n",
            "Epoch 199/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4744 - acc: 0.8919 - val_loss: 0.4374 - val_acc: 0.9048\n",
            "Epoch 200/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4733 - acc: 0.8922 - val_loss: 0.4367 - val_acc: 0.9052\n",
            "Epoch 201/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4724 - acc: 0.8924 - val_loss: 0.4357 - val_acc: 0.9048\n",
            "Epoch 202/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4714 - acc: 0.8921 - val_loss: 0.4348 - val_acc: 0.9052\n",
            "Epoch 203/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4704 - acc: 0.8926 - val_loss: 0.4341 - val_acc: 0.9048\n",
            "Epoch 204/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4694 - acc: 0.8927 - val_loss: 0.4335 - val_acc: 0.9048\n",
            "Epoch 205/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4685 - acc: 0.8928 - val_loss: 0.4323 - val_acc: 0.9052\n",
            "Epoch 206/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4675 - acc: 0.8929 - val_loss: 0.4316 - val_acc: 0.9053\n",
            "Epoch 207/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4666 - acc: 0.8930 - val_loss: 0.4311 - val_acc: 0.9055\n",
            "Epoch 208/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4655 - acc: 0.8932 - val_loss: 0.4301 - val_acc: 0.9067\n",
            "Epoch 209/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4646 - acc: 0.8933 - val_loss: 0.4292 - val_acc: 0.9057\n",
            "Epoch 210/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4636 - acc: 0.8935 - val_loss: 0.4287 - val_acc: 0.9052\n",
            "Epoch 211/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4627 - acc: 0.8938 - val_loss: 0.4276 - val_acc: 0.9057\n",
            "Epoch 212/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4619 - acc: 0.8938 - val_loss: 0.4269 - val_acc: 0.9058\n",
            "Epoch 213/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4609 - acc: 0.8939 - val_loss: 0.4261 - val_acc: 0.9060\n",
            "Epoch 214/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4600 - acc: 0.8941 - val_loss: 0.4254 - val_acc: 0.9058\n",
            "Epoch 215/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4591 - acc: 0.8938 - val_loss: 0.4247 - val_acc: 0.9067\n",
            "Epoch 216/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4582 - acc: 0.8942 - val_loss: 0.4240 - val_acc: 0.9055\n",
            "Epoch 217/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4572 - acc: 0.8942 - val_loss: 0.4230 - val_acc: 0.9067\n",
            "Epoch 218/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4563 - acc: 0.8946 - val_loss: 0.4221 - val_acc: 0.9072\n",
            "Epoch 219/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4555 - acc: 0.8947 - val_loss: 0.4214 - val_acc: 0.9063\n",
            "Epoch 220/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4546 - acc: 0.8945 - val_loss: 0.4210 - val_acc: 0.9065\n",
            "Epoch 221/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4537 - acc: 0.8950 - val_loss: 0.4203 - val_acc: 0.9078\n",
            "Epoch 222/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4528 - acc: 0.8952 - val_loss: 0.4194 - val_acc: 0.9073\n",
            "Epoch 223/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4520 - acc: 0.8951 - val_loss: 0.4187 - val_acc: 0.9073\n",
            "Epoch 224/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4511 - acc: 0.8954 - val_loss: 0.4180 - val_acc: 0.9073\n",
            "Epoch 225/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4503 - acc: 0.8956 - val_loss: 0.4174 - val_acc: 0.9078\n",
            "Epoch 226/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4494 - acc: 0.8956 - val_loss: 0.4166 - val_acc: 0.9078\n",
            "Epoch 227/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4487 - acc: 0.8957 - val_loss: 0.4157 - val_acc: 0.9078\n",
            "Epoch 228/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4478 - acc: 0.8959 - val_loss: 0.4151 - val_acc: 0.9072\n",
            "Epoch 229/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4469 - acc: 0.8962 - val_loss: 0.4145 - val_acc: 0.9078\n",
            "Epoch 230/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4461 - acc: 0.8959 - val_loss: 0.4137 - val_acc: 0.9075\n",
            "Epoch 231/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4454 - acc: 0.8963 - val_loss: 0.4132 - val_acc: 0.9078\n",
            "Epoch 232/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4446 - acc: 0.8963 - val_loss: 0.4122 - val_acc: 0.9078\n",
            "Epoch 233/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4438 - acc: 0.8967 - val_loss: 0.4117 - val_acc: 0.9082\n",
            "Epoch 234/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4430 - acc: 0.8968 - val_loss: 0.4110 - val_acc: 0.9080\n",
            "Epoch 235/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4422 - acc: 0.8969 - val_loss: 0.4103 - val_acc: 0.9088\n",
            "Epoch 236/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4416 - acc: 0.8971 - val_loss: 0.4095 - val_acc: 0.9095\n",
            "Epoch 237/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4407 - acc: 0.8971 - val_loss: 0.4087 - val_acc: 0.9087\n",
            "Epoch 238/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4399 - acc: 0.8972 - val_loss: 0.4083 - val_acc: 0.9087\n",
            "Epoch 239/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4391 - acc: 0.8973 - val_loss: 0.4077 - val_acc: 0.9090\n",
            "Epoch 240/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4385 - acc: 0.8976 - val_loss: 0.4067 - val_acc: 0.9088\n",
            "Epoch 241/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4377 - acc: 0.8977 - val_loss: 0.4063 - val_acc: 0.9102\n",
            "Epoch 242/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4371 - acc: 0.8978 - val_loss: 0.4056 - val_acc: 0.9098\n",
            "Epoch 243/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4363 - acc: 0.8979 - val_loss: 0.4052 - val_acc: 0.9092\n",
            "Epoch 244/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4354 - acc: 0.8981 - val_loss: 0.4041 - val_acc: 0.9093\n",
            "Epoch 245/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4347 - acc: 0.8980 - val_loss: 0.4039 - val_acc: 0.9102\n",
            "Epoch 246/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4341 - acc: 0.8984 - val_loss: 0.4032 - val_acc: 0.9095\n",
            "Epoch 247/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4334 - acc: 0.8982 - val_loss: 0.4022 - val_acc: 0.9097\n",
            "Epoch 248/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4325 - acc: 0.8983 - val_loss: 0.4016 - val_acc: 0.9103\n",
            "Epoch 249/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4319 - acc: 0.8984 - val_loss: 0.4010 - val_acc: 0.9103\n",
            "Epoch 250/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4311 - acc: 0.8985 - val_loss: 0.4002 - val_acc: 0.9097\n",
            "Epoch 251/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4305 - acc: 0.8987 - val_loss: 0.3996 - val_acc: 0.9102\n",
            "Epoch 252/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4298 - acc: 0.8985 - val_loss: 0.3988 - val_acc: 0.9102\n",
            "Epoch 253/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4290 - acc: 0.8989 - val_loss: 0.3985 - val_acc: 0.9108\n",
            "Epoch 254/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.4282 - acc: 0.8991 - val_loss: 0.3983 - val_acc: 0.9108\n",
            "Epoch 255/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4277 - acc: 0.8989 - val_loss: 0.3975 - val_acc: 0.9113\n",
            "Epoch 256/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4270 - acc: 0.8990 - val_loss: 0.3968 - val_acc: 0.9100\n",
            "Epoch 257/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4263 - acc: 0.8994 - val_loss: 0.3961 - val_acc: 0.9103\n",
            "Epoch 258/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4255 - acc: 0.8994 - val_loss: 0.3955 - val_acc: 0.9103\n",
            "Epoch 259/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4250 - acc: 0.8994 - val_loss: 0.3946 - val_acc: 0.9105\n",
            "Epoch 260/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4244 - acc: 0.8995 - val_loss: 0.3944 - val_acc: 0.9102\n",
            "Epoch 261/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4235 - acc: 0.8995 - val_loss: 0.3938 - val_acc: 0.9112\n",
            "Epoch 262/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4231 - acc: 0.8997 - val_loss: 0.3932 - val_acc: 0.9103\n",
            "Epoch 263/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4223 - acc: 0.8997 - val_loss: 0.3926 - val_acc: 0.9112\n",
            "Epoch 264/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4217 - acc: 0.9001 - val_loss: 0.3924 - val_acc: 0.9107\n",
            "Epoch 265/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4209 - acc: 0.9002 - val_loss: 0.3920 - val_acc: 0.9112\n",
            "Epoch 266/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4204 - acc: 0.9001 - val_loss: 0.3913 - val_acc: 0.9105\n",
            "Epoch 267/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4197 - acc: 0.9003 - val_loss: 0.3905 - val_acc: 0.9117\n",
            "Epoch 268/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4191 - acc: 0.9003 - val_loss: 0.3900 - val_acc: 0.9112\n",
            "Epoch 269/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4185 - acc: 0.9004 - val_loss: 0.3894 - val_acc: 0.9113\n",
            "Epoch 270/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4180 - acc: 0.9003 - val_loss: 0.3888 - val_acc: 0.9115\n",
            "Epoch 271/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4171 - acc: 0.9006 - val_loss: 0.3880 - val_acc: 0.9118\n",
            "Epoch 272/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4167 - acc: 0.9006 - val_loss: 0.3880 - val_acc: 0.9112\n",
            "Epoch 273/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4160 - acc: 0.9007 - val_loss: 0.3876 - val_acc: 0.9115\n",
            "Epoch 274/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4153 - acc: 0.9008 - val_loss: 0.3867 - val_acc: 0.9120\n",
            "Epoch 275/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.4147 - acc: 0.9010 - val_loss: 0.3865 - val_acc: 0.9123\n",
            "Epoch 276/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4141 - acc: 0.9011 - val_loss: 0.3860 - val_acc: 0.9115\n",
            "Epoch 277/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4135 - acc: 0.9011 - val_loss: 0.3856 - val_acc: 0.9115\n",
            "Epoch 278/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4130 - acc: 0.9011 - val_loss: 0.3850 - val_acc: 0.9118\n",
            "Epoch 279/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4123 - acc: 0.9016 - val_loss: 0.3844 - val_acc: 0.9118\n",
            "Epoch 280/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4117 - acc: 0.9015 - val_loss: 0.3841 - val_acc: 0.9118\n",
            "Epoch 281/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4110 - acc: 0.9018 - val_loss: 0.3835 - val_acc: 0.9130\n",
            "Epoch 282/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4104 - acc: 0.9019 - val_loss: 0.3827 - val_acc: 0.9123\n",
            "Epoch 283/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4099 - acc: 0.9018 - val_loss: 0.3825 - val_acc: 0.9123\n",
            "Epoch 284/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4093 - acc: 0.9022 - val_loss: 0.3819 - val_acc: 0.9123\n",
            "Epoch 285/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4088 - acc: 0.9022 - val_loss: 0.3812 - val_acc: 0.9120\n",
            "Epoch 286/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4083 - acc: 0.9019 - val_loss: 0.3810 - val_acc: 0.9120\n",
            "Epoch 287/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4077 - acc: 0.9022 - val_loss: 0.3805 - val_acc: 0.9130\n",
            "Epoch 288/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4070 - acc: 0.9026 - val_loss: 0.3799 - val_acc: 0.9112\n",
            "Epoch 289/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4064 - acc: 0.9027 - val_loss: 0.3794 - val_acc: 0.9127\n",
            "Epoch 290/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4058 - acc: 0.9029 - val_loss: 0.3789 - val_acc: 0.9132\n",
            "Epoch 291/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4053 - acc: 0.9028 - val_loss: 0.3787 - val_acc: 0.9137\n",
            "Epoch 292/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.4047 - acc: 0.9031 - val_loss: 0.3783 - val_acc: 0.9128\n",
            "Epoch 293/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4042 - acc: 0.9028 - val_loss: 0.3777 - val_acc: 0.9137\n",
            "Epoch 294/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4037 - acc: 0.9029 - val_loss: 0.3774 - val_acc: 0.9132\n",
            "Epoch 295/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4031 - acc: 0.9032 - val_loss: 0.3768 - val_acc: 0.9137\n",
            "Epoch 296/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4026 - acc: 0.9033 - val_loss: 0.3762 - val_acc: 0.9143\n",
            "Epoch 297/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4019 - acc: 0.9035 - val_loss: 0.3759 - val_acc: 0.9135\n",
            "Epoch 298/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.4014 - acc: 0.9036 - val_loss: 0.3753 - val_acc: 0.9130\n",
            "Epoch 299/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4008 - acc: 0.9037 - val_loss: 0.3751 - val_acc: 0.9137\n",
            "Epoch 300/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.4003 - acc: 0.9038 - val_loss: 0.3745 - val_acc: 0.9140\n",
            "Epoch 301/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3997 - acc: 0.9042 - val_loss: 0.3742 - val_acc: 0.9133\n",
            "Epoch 302/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3993 - acc: 0.9039 - val_loss: 0.3739 - val_acc: 0.9138\n",
            "Epoch 303/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3987 - acc: 0.9042 - val_loss: 0.3732 - val_acc: 0.9143\n",
            "Epoch 304/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3982 - acc: 0.9044 - val_loss: 0.3728 - val_acc: 0.9147\n",
            "Epoch 305/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3977 - acc: 0.9045 - val_loss: 0.3725 - val_acc: 0.9143\n",
            "Epoch 306/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3971 - acc: 0.9046 - val_loss: 0.3723 - val_acc: 0.9143\n",
            "Epoch 307/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3968 - acc: 0.9046 - val_loss: 0.3715 - val_acc: 0.9142\n",
            "Epoch 308/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3962 - acc: 0.9047 - val_loss: 0.3714 - val_acc: 0.9135\n",
            "Epoch 309/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3956 - acc: 0.9048 - val_loss: 0.3706 - val_acc: 0.9147\n",
            "Epoch 310/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3952 - acc: 0.9050 - val_loss: 0.3698 - val_acc: 0.9142\n",
            "Epoch 311/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3946 - acc: 0.9051 - val_loss: 0.3699 - val_acc: 0.9140\n",
            "Epoch 312/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3942 - acc: 0.9052 - val_loss: 0.3693 - val_acc: 0.9145\n",
            "Epoch 313/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3936 - acc: 0.9053 - val_loss: 0.3692 - val_acc: 0.9152\n",
            "Epoch 314/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3933 - acc: 0.9051 - val_loss: 0.3688 - val_acc: 0.9150\n",
            "Epoch 315/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3926 - acc: 0.9054 - val_loss: 0.3681 - val_acc: 0.9150\n",
            "Epoch 316/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3922 - acc: 0.9056 - val_loss: 0.3674 - val_acc: 0.9143\n",
            "Epoch 317/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3917 - acc: 0.9055 - val_loss: 0.3671 - val_acc: 0.9157\n",
            "Epoch 318/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3912 - acc: 0.9056 - val_loss: 0.3672 - val_acc: 0.9152\n",
            "Epoch 319/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3906 - acc: 0.9056 - val_loss: 0.3666 - val_acc: 0.9157\n",
            "Epoch 320/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3902 - acc: 0.9059 - val_loss: 0.3660 - val_acc: 0.9148\n",
            "Epoch 321/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3896 - acc: 0.9059 - val_loss: 0.3654 - val_acc: 0.9152\n",
            "Epoch 322/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3892 - acc: 0.9061 - val_loss: 0.3653 - val_acc: 0.9158\n",
            "Epoch 323/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3887 - acc: 0.9061 - val_loss: 0.3647 - val_acc: 0.9150\n",
            "Epoch 324/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3883 - acc: 0.9064 - val_loss: 0.3640 - val_acc: 0.9157\n",
            "Epoch 325/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3879 - acc: 0.9062 - val_loss: 0.3637 - val_acc: 0.9155\n",
            "Epoch 326/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3874 - acc: 0.9066 - val_loss: 0.3634 - val_acc: 0.9152\n",
            "Epoch 327/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3869 - acc: 0.9065 - val_loss: 0.3633 - val_acc: 0.9158\n",
            "Epoch 328/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3864 - acc: 0.9067 - val_loss: 0.3630 - val_acc: 0.9152\n",
            "Epoch 329/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3859 - acc: 0.9068 - val_loss: 0.3620 - val_acc: 0.9158\n",
            "Epoch 330/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3856 - acc: 0.9067 - val_loss: 0.3620 - val_acc: 0.9152\n",
            "Epoch 331/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3850 - acc: 0.9069 - val_loss: 0.3615 - val_acc: 0.9143\n",
            "Epoch 332/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3845 - acc: 0.9073 - val_loss: 0.3614 - val_acc: 0.9150\n",
            "Epoch 333/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3841 - acc: 0.9069 - val_loss: 0.3608 - val_acc: 0.9163\n",
            "Epoch 334/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3837 - acc: 0.9072 - val_loss: 0.3604 - val_acc: 0.9162\n",
            "Epoch 335/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3833 - acc: 0.9072 - val_loss: 0.3599 - val_acc: 0.9162\n",
            "Epoch 336/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3828 - acc: 0.9072 - val_loss: 0.3598 - val_acc: 0.9155\n",
            "Epoch 337/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3825 - acc: 0.9073 - val_loss: 0.3595 - val_acc: 0.9157\n",
            "Epoch 338/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3820 - acc: 0.9075 - val_loss: 0.3591 - val_acc: 0.9150\n",
            "Epoch 339/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3817 - acc: 0.9078 - val_loss: 0.3585 - val_acc: 0.9170\n",
            "Epoch 340/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3811 - acc: 0.9078 - val_loss: 0.3581 - val_acc: 0.9155\n",
            "Epoch 341/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3806 - acc: 0.9078 - val_loss: 0.3580 - val_acc: 0.9163\n",
            "Epoch 342/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3801 - acc: 0.9078 - val_loss: 0.3572 - val_acc: 0.9167\n",
            "Epoch 343/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3797 - acc: 0.9080 - val_loss: 0.3567 - val_acc: 0.9158\n",
            "Epoch 344/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3794 - acc: 0.9080 - val_loss: 0.3566 - val_acc: 0.9173\n",
            "Epoch 345/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3789 - acc: 0.9082 - val_loss: 0.3563 - val_acc: 0.9167\n",
            "Epoch 346/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3785 - acc: 0.9082 - val_loss: 0.3558 - val_acc: 0.9177\n",
            "Epoch 347/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3780 - acc: 0.9085 - val_loss: 0.3555 - val_acc: 0.9178\n",
            "Epoch 348/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3776 - acc: 0.9083 - val_loss: 0.3553 - val_acc: 0.9168\n",
            "Epoch 349/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3774 - acc: 0.9085 - val_loss: 0.3552 - val_acc: 0.9177\n",
            "Epoch 350/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3769 - acc: 0.9083 - val_loss: 0.3544 - val_acc: 0.9170\n",
            "Epoch 351/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3764 - acc: 0.9086 - val_loss: 0.3541 - val_acc: 0.9177\n",
            "Epoch 352/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3758 - acc: 0.9087 - val_loss: 0.3538 - val_acc: 0.9173\n",
            "Epoch 353/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3756 - acc: 0.9085 - val_loss: 0.3534 - val_acc: 0.9173\n",
            "Epoch 354/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3751 - acc: 0.9088 - val_loss: 0.3530 - val_acc: 0.9177\n",
            "Epoch 355/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3747 - acc: 0.9088 - val_loss: 0.3528 - val_acc: 0.9180\n",
            "Epoch 356/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3743 - acc: 0.9089 - val_loss: 0.3527 - val_acc: 0.9178\n",
            "Epoch 357/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3739 - acc: 0.9090 - val_loss: 0.3522 - val_acc: 0.9185\n",
            "Epoch 358/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3734 - acc: 0.9090 - val_loss: 0.3517 - val_acc: 0.9180\n",
            "Epoch 359/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3731 - acc: 0.9090 - val_loss: 0.3516 - val_acc: 0.9173\n",
            "Epoch 360/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3727 - acc: 0.9089 - val_loss: 0.3510 - val_acc: 0.9177\n",
            "Epoch 361/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3724 - acc: 0.9092 - val_loss: 0.3508 - val_acc: 0.9185\n",
            "Epoch 362/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3720 - acc: 0.9091 - val_loss: 0.3505 - val_acc: 0.9188\n",
            "Epoch 363/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3717 - acc: 0.9092 - val_loss: 0.3501 - val_acc: 0.9182\n",
            "Epoch 364/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3712 - acc: 0.9093 - val_loss: 0.3498 - val_acc: 0.9190\n",
            "Epoch 365/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3710 - acc: 0.9094 - val_loss: 0.3493 - val_acc: 0.9187\n",
            "Epoch 366/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3703 - acc: 0.9096 - val_loss: 0.3487 - val_acc: 0.9188\n",
            "Epoch 367/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3700 - acc: 0.9096 - val_loss: 0.3486 - val_acc: 0.9192\n",
            "Epoch 368/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3697 - acc: 0.9098 - val_loss: 0.3481 - val_acc: 0.9195\n",
            "Epoch 369/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3694 - acc: 0.9098 - val_loss: 0.3481 - val_acc: 0.9187\n",
            "Epoch 370/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3691 - acc: 0.9098 - val_loss: 0.3479 - val_acc: 0.9187\n",
            "Epoch 371/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3686 - acc: 0.9100 - val_loss: 0.3474 - val_acc: 0.9185\n",
            "Epoch 372/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3682 - acc: 0.9101 - val_loss: 0.3474 - val_acc: 0.9198\n",
            "Epoch 373/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3678 - acc: 0.9099 - val_loss: 0.3468 - val_acc: 0.9193\n",
            "Epoch 374/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3675 - acc: 0.9101 - val_loss: 0.3465 - val_acc: 0.9190\n",
            "Epoch 375/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3672 - acc: 0.9101 - val_loss: 0.3458 - val_acc: 0.9198\n",
            "Epoch 376/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3668 - acc: 0.9103 - val_loss: 0.3461 - val_acc: 0.9182\n",
            "Epoch 377/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3665 - acc: 0.9103 - val_loss: 0.3456 - val_acc: 0.9197\n",
            "Epoch 378/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3660 - acc: 0.9105 - val_loss: 0.3454 - val_acc: 0.9190\n",
            "Epoch 379/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3658 - acc: 0.9107 - val_loss: 0.3450 - val_acc: 0.9193\n",
            "Epoch 380/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3655 - acc: 0.9107 - val_loss: 0.3448 - val_acc: 0.9198\n",
            "Epoch 381/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3651 - acc: 0.9105 - val_loss: 0.3445 - val_acc: 0.9188\n",
            "Epoch 382/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3646 - acc: 0.9107 - val_loss: 0.3439 - val_acc: 0.9192\n",
            "Epoch 383/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3644 - acc: 0.9110 - val_loss: 0.3438 - val_acc: 0.9197\n",
            "Epoch 384/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3640 - acc: 0.9108 - val_loss: 0.3434 - val_acc: 0.9198\n",
            "Epoch 385/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3637 - acc: 0.9108 - val_loss: 0.3432 - val_acc: 0.9197\n",
            "Epoch 386/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3633 - acc: 0.9111 - val_loss: 0.3430 - val_acc: 0.9185\n",
            "Epoch 387/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3631 - acc: 0.9112 - val_loss: 0.3429 - val_acc: 0.9192\n",
            "Epoch 388/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3625 - acc: 0.9114 - val_loss: 0.3422 - val_acc: 0.9193\n",
            "Epoch 389/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3623 - acc: 0.9114 - val_loss: 0.3421 - val_acc: 0.9193\n",
            "Epoch 390/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3618 - acc: 0.9113 - val_loss: 0.3418 - val_acc: 0.9198\n",
            "Epoch 391/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3615 - acc: 0.9114 - val_loss: 0.3414 - val_acc: 0.9202\n",
            "Epoch 392/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3613 - acc: 0.9113 - val_loss: 0.3412 - val_acc: 0.9203\n",
            "Epoch 393/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3609 - acc: 0.9116 - val_loss: 0.3410 - val_acc: 0.9198\n",
            "Epoch 394/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3606 - acc: 0.9116 - val_loss: 0.3408 - val_acc: 0.9198\n",
            "Epoch 395/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3602 - acc: 0.9115 - val_loss: 0.3405 - val_acc: 0.9203\n",
            "Epoch 396/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3599 - acc: 0.9117 - val_loss: 0.3403 - val_acc: 0.9202\n",
            "Epoch 397/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3596 - acc: 0.9115 - val_loss: 0.3404 - val_acc: 0.9202\n",
            "Epoch 398/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3594 - acc: 0.9117 - val_loss: 0.3396 - val_acc: 0.9198\n",
            "Epoch 399/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3590 - acc: 0.9120 - val_loss: 0.3392 - val_acc: 0.9203\n",
            "Epoch 400/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3586 - acc: 0.9119 - val_loss: 0.3390 - val_acc: 0.9210\n",
            "Epoch 401/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3583 - acc: 0.9119 - val_loss: 0.3388 - val_acc: 0.9205\n",
            "Epoch 402/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3580 - acc: 0.9118 - val_loss: 0.3384 - val_acc: 0.9205\n",
            "Epoch 403/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3577 - acc: 0.9117 - val_loss: 0.3386 - val_acc: 0.9205\n",
            "Epoch 404/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3573 - acc: 0.9119 - val_loss: 0.3381 - val_acc: 0.9205\n",
            "Epoch 405/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3570 - acc: 0.9122 - val_loss: 0.3375 - val_acc: 0.9200\n",
            "Epoch 406/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3568 - acc: 0.9121 - val_loss: 0.3379 - val_acc: 0.9205\n",
            "Epoch 407/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3565 - acc: 0.9119 - val_loss: 0.3373 - val_acc: 0.9212\n",
            "Epoch 408/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3561 - acc: 0.9123 - val_loss: 0.3371 - val_acc: 0.9212\n",
            "Epoch 409/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3558 - acc: 0.9122 - val_loss: 0.3372 - val_acc: 0.9203\n",
            "Epoch 410/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3556 - acc: 0.9122 - val_loss: 0.3366 - val_acc: 0.9203\n",
            "Epoch 411/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3552 - acc: 0.9124 - val_loss: 0.3366 - val_acc: 0.9197\n",
            "Epoch 412/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3549 - acc: 0.9122 - val_loss: 0.3361 - val_acc: 0.9203\n",
            "Epoch 413/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3545 - acc: 0.9125 - val_loss: 0.3357 - val_acc: 0.9208\n",
            "Epoch 414/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3544 - acc: 0.9125 - val_loss: 0.3355 - val_acc: 0.9200\n",
            "Epoch 415/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3542 - acc: 0.9126 - val_loss: 0.3352 - val_acc: 0.9208\n",
            "Epoch 416/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3537 - acc: 0.9128 - val_loss: 0.3354 - val_acc: 0.9200\n",
            "Epoch 417/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3535 - acc: 0.9125 - val_loss: 0.3350 - val_acc: 0.9208\n",
            "Epoch 418/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3531 - acc: 0.9129 - val_loss: 0.3345 - val_acc: 0.9212\n",
            "Epoch 419/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3528 - acc: 0.9128 - val_loss: 0.3347 - val_acc: 0.9200\n",
            "Epoch 420/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3526 - acc: 0.9125 - val_loss: 0.3341 - val_acc: 0.9208\n",
            "Epoch 421/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3523 - acc: 0.9128 - val_loss: 0.3339 - val_acc: 0.9202\n",
            "Epoch 422/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3520 - acc: 0.9129 - val_loss: 0.3335 - val_acc: 0.9208\n",
            "Epoch 423/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3516 - acc: 0.9128 - val_loss: 0.3331 - val_acc: 0.9212\n",
            "Epoch 424/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3515 - acc: 0.9129 - val_loss: 0.3331 - val_acc: 0.9218\n",
            "Epoch 425/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3510 - acc: 0.9131 - val_loss: 0.3329 - val_acc: 0.9213\n",
            "Epoch 426/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3508 - acc: 0.9132 - val_loss: 0.3324 - val_acc: 0.9215\n",
            "Epoch 427/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3506 - acc: 0.9130 - val_loss: 0.3325 - val_acc: 0.9207\n",
            "Epoch 428/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3502 - acc: 0.9131 - val_loss: 0.3319 - val_acc: 0.9210\n",
            "Epoch 429/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3498 - acc: 0.9133 - val_loss: 0.3318 - val_acc: 0.9207\n",
            "Epoch 430/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3497 - acc: 0.9131 - val_loss: 0.3315 - val_acc: 0.9212\n",
            "Epoch 431/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3493 - acc: 0.9134 - val_loss: 0.3314 - val_acc: 0.9205\n",
            "Epoch 432/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3491 - acc: 0.9133 - val_loss: 0.3313 - val_acc: 0.9207\n",
            "Epoch 433/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3487 - acc: 0.9138 - val_loss: 0.3311 - val_acc: 0.9213\n",
            "Epoch 434/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3485 - acc: 0.9135 - val_loss: 0.3306 - val_acc: 0.9218\n",
            "Epoch 435/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3481 - acc: 0.9136 - val_loss: 0.3304 - val_acc: 0.9207\n",
            "Epoch 436/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3479 - acc: 0.9134 - val_loss: 0.3301 - val_acc: 0.9208\n",
            "Epoch 437/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3475 - acc: 0.9138 - val_loss: 0.3298 - val_acc: 0.9208\n",
            "Epoch 438/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3474 - acc: 0.9137 - val_loss: 0.3298 - val_acc: 0.9208\n",
            "Epoch 439/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3470 - acc: 0.9137 - val_loss: 0.3296 - val_acc: 0.9210\n",
            "Epoch 440/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3467 - acc: 0.9137 - val_loss: 0.3294 - val_acc: 0.9215\n",
            "Epoch 441/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3464 - acc: 0.9137 - val_loss: 0.3291 - val_acc: 0.9217\n",
            "Epoch 442/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3463 - acc: 0.9137 - val_loss: 0.3286 - val_acc: 0.9213\n",
            "Epoch 443/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3459 - acc: 0.9135 - val_loss: 0.3287 - val_acc: 0.9217\n",
            "Epoch 444/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3456 - acc: 0.9140 - val_loss: 0.3284 - val_acc: 0.9202\n",
            "Epoch 445/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3454 - acc: 0.9142 - val_loss: 0.3283 - val_acc: 0.9220\n",
            "Epoch 446/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3452 - acc: 0.9138 - val_loss: 0.3278 - val_acc: 0.9218\n",
            "Epoch 447/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3448 - acc: 0.9142 - val_loss: 0.3276 - val_acc: 0.9217\n",
            "Epoch 448/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3445 - acc: 0.9141 - val_loss: 0.3275 - val_acc: 0.9225\n",
            "Epoch 449/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3443 - acc: 0.9142 - val_loss: 0.3273 - val_acc: 0.9215\n",
            "Epoch 450/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3439 - acc: 0.9143 - val_loss: 0.3273 - val_acc: 0.9225\n",
            "Epoch 451/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3438 - acc: 0.9141 - val_loss: 0.3270 - val_acc: 0.9227\n",
            "Epoch 452/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3435 - acc: 0.9146 - val_loss: 0.3265 - val_acc: 0.9223\n",
            "Epoch 453/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3431 - acc: 0.9144 - val_loss: 0.3264 - val_acc: 0.9223\n",
            "Epoch 454/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3429 - acc: 0.9145 - val_loss: 0.3262 - val_acc: 0.9222\n",
            "Epoch 455/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3426 - acc: 0.9145 - val_loss: 0.3259 - val_acc: 0.9230\n",
            "Epoch 456/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3423 - acc: 0.9145 - val_loss: 0.3259 - val_acc: 0.9222\n",
            "Epoch 457/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3422 - acc: 0.9146 - val_loss: 0.3257 - val_acc: 0.9220\n",
            "Epoch 458/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3419 - acc: 0.9146 - val_loss: 0.3254 - val_acc: 0.9220\n",
            "Epoch 459/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3416 - acc: 0.9146 - val_loss: 0.3254 - val_acc: 0.9227\n",
            "Epoch 460/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3414 - acc: 0.9149 - val_loss: 0.3248 - val_acc: 0.9233\n",
            "Epoch 461/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3410 - acc: 0.9147 - val_loss: 0.3247 - val_acc: 0.9227\n",
            "Epoch 462/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3408 - acc: 0.9149 - val_loss: 0.3245 - val_acc: 0.9225\n",
            "Epoch 463/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3406 - acc: 0.9147 - val_loss: 0.3244 - val_acc: 0.9220\n",
            "Epoch 464/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3402 - acc: 0.9149 - val_loss: 0.3242 - val_acc: 0.9228\n",
            "Epoch 465/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3400 - acc: 0.9152 - val_loss: 0.3236 - val_acc: 0.9232\n",
            "Epoch 466/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3399 - acc: 0.9149 - val_loss: 0.3235 - val_acc: 0.9232\n",
            "Epoch 467/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3394 - acc: 0.9153 - val_loss: 0.3234 - val_acc: 0.9235\n",
            "Epoch 468/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3392 - acc: 0.9150 - val_loss: 0.3232 - val_acc: 0.9233\n",
            "Epoch 469/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3390 - acc: 0.9152 - val_loss: 0.3227 - val_acc: 0.9228\n",
            "Epoch 470/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3388 - acc: 0.9150 - val_loss: 0.3230 - val_acc: 0.9228\n",
            "Epoch 471/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3385 - acc: 0.9152 - val_loss: 0.3226 - val_acc: 0.9228\n",
            "Epoch 472/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3382 - acc: 0.9153 - val_loss: 0.3227 - val_acc: 0.9238\n",
            "Epoch 473/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3381 - acc: 0.9152 - val_loss: 0.3223 - val_acc: 0.9232\n",
            "Epoch 474/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3378 - acc: 0.9153 - val_loss: 0.3222 - val_acc: 0.9228\n",
            "Epoch 475/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3375 - acc: 0.9154 - val_loss: 0.3214 - val_acc: 0.9227\n",
            "Epoch 476/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3372 - acc: 0.9156 - val_loss: 0.3214 - val_acc: 0.9233\n",
            "Epoch 477/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3369 - acc: 0.9154 - val_loss: 0.3212 - val_acc: 0.9230\n",
            "Epoch 478/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3367 - acc: 0.9154 - val_loss: 0.3212 - val_acc: 0.9235\n",
            "Epoch 479/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3364 - acc: 0.9156 - val_loss: 0.3211 - val_acc: 0.9232\n",
            "Epoch 480/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3364 - acc: 0.9153 - val_loss: 0.3207 - val_acc: 0.9235\n",
            "Epoch 481/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3360 - acc: 0.9155 - val_loss: 0.3207 - val_acc: 0.9237\n",
            "Epoch 482/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3356 - acc: 0.9158 - val_loss: 0.3204 - val_acc: 0.9237\n",
            "Epoch 483/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3354 - acc: 0.9157 - val_loss: 0.3205 - val_acc: 0.9228\n",
            "Epoch 484/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3352 - acc: 0.9157 - val_loss: 0.3199 - val_acc: 0.9223\n",
            "Epoch 485/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3350 - acc: 0.9155 - val_loss: 0.3199 - val_acc: 0.9237\n",
            "Epoch 486/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3347 - acc: 0.9160 - val_loss: 0.3198 - val_acc: 0.9232\n",
            "Epoch 487/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3344 - acc: 0.9158 - val_loss: 0.3197 - val_acc: 0.9235\n",
            "Epoch 488/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3342 - acc: 0.9157 - val_loss: 0.3190 - val_acc: 0.9228\n",
            "Epoch 489/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3341 - acc: 0.9159 - val_loss: 0.3192 - val_acc: 0.9228\n",
            "Epoch 490/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3338 - acc: 0.9160 - val_loss: 0.3192 - val_acc: 0.9237\n",
            "Epoch 491/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3337 - acc: 0.9161 - val_loss: 0.3187 - val_acc: 0.9235\n",
            "Epoch 492/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3333 - acc: 0.9159 - val_loss: 0.3186 - val_acc: 0.9233\n",
            "Epoch 493/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3331 - acc: 0.9161 - val_loss: 0.3185 - val_acc: 0.9240\n",
            "Epoch 494/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3328 - acc: 0.9163 - val_loss: 0.3182 - val_acc: 0.9232\n",
            "Epoch 495/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3326 - acc: 0.9160 - val_loss: 0.3184 - val_acc: 0.9240\n",
            "Epoch 496/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3324 - acc: 0.9162 - val_loss: 0.3182 - val_acc: 0.9242\n",
            "Epoch 497/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3323 - acc: 0.9161 - val_loss: 0.3180 - val_acc: 0.9243\n",
            "Epoch 498/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3318 - acc: 0.9163 - val_loss: 0.3176 - val_acc: 0.9235\n",
            "Epoch 499/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3319 - acc: 0.9162 - val_loss: 0.3172 - val_acc: 0.9238\n",
            "Epoch 500/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3316 - acc: 0.9163 - val_loss: 0.3172 - val_acc: 0.9237\n",
            "Epoch 501/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3312 - acc: 0.9163 - val_loss: 0.3170 - val_acc: 0.9237\n",
            "Epoch 502/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3310 - acc: 0.9164 - val_loss: 0.3169 - val_acc: 0.9237\n",
            "Epoch 503/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3307 - acc: 0.9166 - val_loss: 0.3167 - val_acc: 0.9235\n",
            "Epoch 504/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3304 - acc: 0.9165 - val_loss: 0.3165 - val_acc: 0.9233\n",
            "Epoch 505/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3303 - acc: 0.9165 - val_loss: 0.3163 - val_acc: 0.9227\n",
            "Epoch 506/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3301 - acc: 0.9167 - val_loss: 0.3159 - val_acc: 0.9233\n",
            "Epoch 507/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3299 - acc: 0.9166 - val_loss: 0.3162 - val_acc: 0.9238\n",
            "Epoch 508/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3298 - acc: 0.9166 - val_loss: 0.3158 - val_acc: 0.9232\n",
            "Epoch 509/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3294 - acc: 0.9166 - val_loss: 0.3156 - val_acc: 0.9242\n",
            "Epoch 510/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3293 - acc: 0.9165 - val_loss: 0.3154 - val_acc: 0.9233\n",
            "Epoch 511/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3291 - acc: 0.9167 - val_loss: 0.3150 - val_acc: 0.9232\n",
            "Epoch 512/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3288 - acc: 0.9165 - val_loss: 0.3149 - val_acc: 0.9232\n",
            "Epoch 513/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3284 - acc: 0.9169 - val_loss: 0.3148 - val_acc: 0.9233\n",
            "Epoch 514/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3283 - acc: 0.9169 - val_loss: 0.3151 - val_acc: 0.9228\n",
            "Epoch 515/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3282 - acc: 0.9167 - val_loss: 0.3147 - val_acc: 0.9233\n",
            "Epoch 516/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3279 - acc: 0.9169 - val_loss: 0.3143 - val_acc: 0.9233\n",
            "Epoch 517/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3276 - acc: 0.9169 - val_loss: 0.3142 - val_acc: 0.9235\n",
            "Epoch 518/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3273 - acc: 0.9170 - val_loss: 0.3140 - val_acc: 0.9240\n",
            "Epoch 519/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3273 - acc: 0.9167 - val_loss: 0.3140 - val_acc: 0.9235\n",
            "Epoch 520/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3271 - acc: 0.9169 - val_loss: 0.3136 - val_acc: 0.9235\n",
            "Epoch 521/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3271 - acc: 0.9168 - val_loss: 0.3136 - val_acc: 0.9233\n",
            "Epoch 522/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3266 - acc: 0.9170 - val_loss: 0.3132 - val_acc: 0.9242\n",
            "Epoch 523/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3264 - acc: 0.9173 - val_loss: 0.3130 - val_acc: 0.9235\n",
            "Epoch 524/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3261 - acc: 0.9172 - val_loss: 0.3131 - val_acc: 0.9233\n",
            "Epoch 525/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3258 - acc: 0.9170 - val_loss: 0.3127 - val_acc: 0.9235\n",
            "Epoch 526/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3258 - acc: 0.9171 - val_loss: 0.3125 - val_acc: 0.9238\n",
            "Epoch 527/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3255 - acc: 0.9172 - val_loss: 0.3125 - val_acc: 0.9238\n",
            "Epoch 528/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3254 - acc: 0.9171 - val_loss: 0.3122 - val_acc: 0.9233\n",
            "Epoch 529/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3252 - acc: 0.9169 - val_loss: 0.3120 - val_acc: 0.9237\n",
            "Epoch 530/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3251 - acc: 0.9171 - val_loss: 0.3121 - val_acc: 0.9238\n",
            "Epoch 531/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3246 - acc: 0.9173 - val_loss: 0.3115 - val_acc: 0.9237\n",
            "Epoch 532/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3244 - acc: 0.9174 - val_loss: 0.3114 - val_acc: 0.9235\n",
            "Epoch 533/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3242 - acc: 0.9176 - val_loss: 0.3115 - val_acc: 0.9237\n",
            "Epoch 534/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3241 - acc: 0.9174 - val_loss: 0.3115 - val_acc: 0.9242\n",
            "Epoch 535/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3239 - acc: 0.9174 - val_loss: 0.3113 - val_acc: 0.9240\n",
            "Epoch 536/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3238 - acc: 0.9173 - val_loss: 0.3112 - val_acc: 0.9235\n",
            "Epoch 537/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3235 - acc: 0.9176 - val_loss: 0.3111 - val_acc: 0.9232\n",
            "Epoch 538/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3232 - acc: 0.9176 - val_loss: 0.3108 - val_acc: 0.9235\n",
            "Epoch 539/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3231 - acc: 0.9176 - val_loss: 0.3105 - val_acc: 0.9237\n",
            "Epoch 540/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3228 - acc: 0.9176 - val_loss: 0.3107 - val_acc: 0.9240\n",
            "Epoch 541/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3226 - acc: 0.9176 - val_loss: 0.3104 - val_acc: 0.9238\n",
            "Epoch 542/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3226 - acc: 0.9176 - val_loss: 0.3103 - val_acc: 0.9233\n",
            "Epoch 543/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3222 - acc: 0.9177 - val_loss: 0.3103 - val_acc: 0.9240\n",
            "Epoch 544/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3221 - acc: 0.9176 - val_loss: 0.3101 - val_acc: 0.9237\n",
            "Epoch 545/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3219 - acc: 0.9177 - val_loss: 0.3102 - val_acc: 0.9233\n",
            "Epoch 546/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3217 - acc: 0.9179 - val_loss: 0.3099 - val_acc: 0.9237\n",
            "Epoch 547/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3215 - acc: 0.9178 - val_loss: 0.3097 - val_acc: 0.9235\n",
            "Epoch 548/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3212 - acc: 0.9179 - val_loss: 0.3097 - val_acc: 0.9235\n",
            "Epoch 549/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3213 - acc: 0.9178 - val_loss: 0.3097 - val_acc: 0.9237\n",
            "Epoch 550/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3212 - acc: 0.9176 - val_loss: 0.3091 - val_acc: 0.9233\n",
            "Epoch 551/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3209 - acc: 0.9181 - val_loss: 0.3087 - val_acc: 0.9230\n",
            "Epoch 552/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3205 - acc: 0.9180 - val_loss: 0.3090 - val_acc: 0.9235\n",
            "Epoch 553/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3203 - acc: 0.9181 - val_loss: 0.3090 - val_acc: 0.9237\n",
            "Epoch 554/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3201 - acc: 0.9181 - val_loss: 0.3085 - val_acc: 0.9232\n",
            "Epoch 555/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3200 - acc: 0.9181 - val_loss: 0.3084 - val_acc: 0.9235\n",
            "Epoch 556/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3198 - acc: 0.9182 - val_loss: 0.3083 - val_acc: 0.9233\n",
            "Epoch 557/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3195 - acc: 0.9181 - val_loss: 0.3080 - val_acc: 0.9240\n",
            "Epoch 558/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3192 - acc: 0.9183 - val_loss: 0.3078 - val_acc: 0.9238\n",
            "Epoch 559/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3192 - acc: 0.9181 - val_loss: 0.3076 - val_acc: 0.9235\n",
            "Epoch 560/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3189 - acc: 0.9182 - val_loss: 0.3075 - val_acc: 0.9235\n",
            "Epoch 561/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3187 - acc: 0.9185 - val_loss: 0.3075 - val_acc: 0.9233\n",
            "Epoch 562/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3186 - acc: 0.9183 - val_loss: 0.3071 - val_acc: 0.9228\n",
            "Epoch 563/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3185 - acc: 0.9184 - val_loss: 0.3071 - val_acc: 0.9243\n",
            "Epoch 564/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3182 - acc: 0.9187 - val_loss: 0.3072 - val_acc: 0.9235\n",
            "Epoch 565/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3181 - acc: 0.9182 - val_loss: 0.3070 - val_acc: 0.9240\n",
            "Epoch 566/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3178 - acc: 0.9185 - val_loss: 0.3066 - val_acc: 0.9233\n",
            "Epoch 567/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3177 - acc: 0.9184 - val_loss: 0.3067 - val_acc: 0.9235\n",
            "Epoch 568/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3175 - acc: 0.9185 - val_loss: 0.3065 - val_acc: 0.9243\n",
            "Epoch 569/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3173 - acc: 0.9184 - val_loss: 0.3064 - val_acc: 0.9240\n",
            "Epoch 570/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3171 - acc: 0.9188 - val_loss: 0.3062 - val_acc: 0.9245\n",
            "Epoch 571/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3169 - acc: 0.9187 - val_loss: 0.3059 - val_acc: 0.9235\n",
            "Epoch 572/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3169 - acc: 0.9184 - val_loss: 0.3062 - val_acc: 0.9233\n",
            "Epoch 573/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3167 - acc: 0.9186 - val_loss: 0.3058 - val_acc: 0.9237\n",
            "Epoch 574/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3164 - acc: 0.9186 - val_loss: 0.3054 - val_acc: 0.9242\n",
            "Epoch 575/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3162 - acc: 0.9186 - val_loss: 0.3052 - val_acc: 0.9232\n",
            "Epoch 576/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3160 - acc: 0.9187 - val_loss: 0.3055 - val_acc: 0.9228\n",
            "Epoch 577/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3159 - acc: 0.9187 - val_loss: 0.3053 - val_acc: 0.9247\n",
            "Epoch 578/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3158 - acc: 0.9188 - val_loss: 0.3052 - val_acc: 0.9238\n",
            "Epoch 579/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3157 - acc: 0.9186 - val_loss: 0.3051 - val_acc: 0.9238\n",
            "Epoch 580/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3154 - acc: 0.9189 - val_loss: 0.3048 - val_acc: 0.9238\n",
            "Epoch 581/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3152 - acc: 0.9191 - val_loss: 0.3049 - val_acc: 0.9243\n",
            "Epoch 582/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3150 - acc: 0.9191 - val_loss: 0.3046 - val_acc: 0.9243\n",
            "Epoch 583/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3147 - acc: 0.9191 - val_loss: 0.3045 - val_acc: 0.9245\n",
            "Epoch 584/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3146 - acc: 0.9189 - val_loss: 0.3044 - val_acc: 0.9233\n",
            "Epoch 585/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3144 - acc: 0.9192 - val_loss: 0.3046 - val_acc: 0.9238\n",
            "Epoch 586/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3143 - acc: 0.9192 - val_loss: 0.3039 - val_acc: 0.9237\n",
            "Epoch 587/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3139 - acc: 0.9191 - val_loss: 0.3037 - val_acc: 0.9240\n",
            "Epoch 588/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3138 - acc: 0.9193 - val_loss: 0.3041 - val_acc: 0.9237\n",
            "Epoch 589/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3138 - acc: 0.9190 - val_loss: 0.3035 - val_acc: 0.9240\n",
            "Epoch 590/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3134 - acc: 0.9194 - val_loss: 0.3035 - val_acc: 0.9235\n",
            "Epoch 591/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3133 - acc: 0.9194 - val_loss: 0.3033 - val_acc: 0.9240\n",
            "Epoch 592/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3132 - acc: 0.9194 - val_loss: 0.3034 - val_acc: 0.9233\n",
            "Epoch 593/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3129 - acc: 0.9195 - val_loss: 0.3033 - val_acc: 0.9237\n",
            "Epoch 594/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3128 - acc: 0.9196 - val_loss: 0.3033 - val_acc: 0.9232\n",
            "Epoch 595/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3125 - acc: 0.9196 - val_loss: 0.3029 - val_acc: 0.9235\n",
            "Epoch 596/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3124 - acc: 0.9195 - val_loss: 0.3029 - val_acc: 0.9238\n",
            "Epoch 597/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3124 - acc: 0.9193 - val_loss: 0.3027 - val_acc: 0.9245\n",
            "Epoch 598/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3120 - acc: 0.9195 - val_loss: 0.3024 - val_acc: 0.9243\n",
            "Epoch 599/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3119 - acc: 0.9195 - val_loss: 0.3025 - val_acc: 0.9238\n",
            "Epoch 600/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3117 - acc: 0.9195 - val_loss: 0.3024 - val_acc: 0.9232\n",
            "Epoch 601/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3117 - acc: 0.9194 - val_loss: 0.3021 - val_acc: 0.9237\n",
            "Epoch 602/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3113 - acc: 0.9195 - val_loss: 0.3018 - val_acc: 0.9233\n",
            "Epoch 603/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3111 - acc: 0.9194 - val_loss: 0.3019 - val_acc: 0.9235\n",
            "Epoch 604/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3112 - acc: 0.9196 - val_loss: 0.3020 - val_acc: 0.9233\n",
            "Epoch 605/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3108 - acc: 0.9197 - val_loss: 0.3017 - val_acc: 0.9235\n",
            "Epoch 606/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3107 - acc: 0.9198 - val_loss: 0.3015 - val_acc: 0.9233\n",
            "Epoch 607/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3105 - acc: 0.9196 - val_loss: 0.3019 - val_acc: 0.9230\n",
            "Epoch 608/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3103 - acc: 0.9200 - val_loss: 0.3011 - val_acc: 0.9232\n",
            "Epoch 609/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3101 - acc: 0.9199 - val_loss: 0.3011 - val_acc: 0.9235\n",
            "Epoch 610/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3099 - acc: 0.9199 - val_loss: 0.3010 - val_acc: 0.9233\n",
            "Epoch 611/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3100 - acc: 0.9199 - val_loss: 0.3009 - val_acc: 0.9237\n",
            "Epoch 612/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3097 - acc: 0.9199 - val_loss: 0.3006 - val_acc: 0.9240\n",
            "Epoch 613/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3094 - acc: 0.9199 - val_loss: 0.3007 - val_acc: 0.9240\n",
            "Epoch 614/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3094 - acc: 0.9201 - val_loss: 0.3004 - val_acc: 0.9237\n",
            "Epoch 615/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3090 - acc: 0.9200 - val_loss: 0.3005 - val_acc: 0.9237\n",
            "Epoch 616/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3089 - acc: 0.9199 - val_loss: 0.3002 - val_acc: 0.9237\n",
            "Epoch 617/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3087 - acc: 0.9200 - val_loss: 0.2998 - val_acc: 0.9247\n",
            "Epoch 618/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3086 - acc: 0.9200 - val_loss: 0.3001 - val_acc: 0.9237\n",
            "Epoch 619/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3084 - acc: 0.9200 - val_loss: 0.2998 - val_acc: 0.9238\n",
            "Epoch 620/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3081 - acc: 0.9201 - val_loss: 0.2998 - val_acc: 0.9230\n",
            "Epoch 621/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3080 - acc: 0.9203 - val_loss: 0.2998 - val_acc: 0.9240\n",
            "Epoch 622/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3078 - acc: 0.9202 - val_loss: 0.2996 - val_acc: 0.9237\n",
            "Epoch 623/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3077 - acc: 0.9203 - val_loss: 0.2995 - val_acc: 0.9243\n",
            "Epoch 624/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3076 - acc: 0.9200 - val_loss: 0.2993 - val_acc: 0.9235\n",
            "Epoch 625/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3075 - acc: 0.9202 - val_loss: 0.2991 - val_acc: 0.9240\n",
            "Epoch 626/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3071 - acc: 0.9204 - val_loss: 0.2992 - val_acc: 0.9233\n",
            "Epoch 627/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3072 - acc: 0.9203 - val_loss: 0.2988 - val_acc: 0.9237\n",
            "Epoch 628/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3069 - acc: 0.9205 - val_loss: 0.2988 - val_acc: 0.9240\n",
            "Epoch 629/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3066 - acc: 0.9201 - val_loss: 0.2987 - val_acc: 0.9233\n",
            "Epoch 630/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3066 - acc: 0.9205 - val_loss: 0.2985 - val_acc: 0.9242\n",
            "Epoch 631/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3063 - acc: 0.9205 - val_loss: 0.2987 - val_acc: 0.9243\n",
            "Epoch 632/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3063 - acc: 0.9203 - val_loss: 0.2986 - val_acc: 0.9240\n",
            "Epoch 633/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3059 - acc: 0.9204 - val_loss: 0.2983 - val_acc: 0.9233\n",
            "Epoch 634/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3057 - acc: 0.9205 - val_loss: 0.2982 - val_acc: 0.9240\n",
            "Epoch 635/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.3056 - acc: 0.9206 - val_loss: 0.2982 - val_acc: 0.9240\n",
            "Epoch 636/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3056 - acc: 0.9205 - val_loss: 0.2976 - val_acc: 0.9247\n",
            "Epoch 637/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3053 - acc: 0.9207 - val_loss: 0.2979 - val_acc: 0.9238\n",
            "Epoch 638/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3051 - acc: 0.9207 - val_loss: 0.2978 - val_acc: 0.9243\n",
            "Epoch 639/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3050 - acc: 0.9206 - val_loss: 0.2977 - val_acc: 0.9242\n",
            "Epoch 640/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3047 - acc: 0.9206 - val_loss: 0.2976 - val_acc: 0.9245\n",
            "Epoch 641/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3047 - acc: 0.9208 - val_loss: 0.2971 - val_acc: 0.9240\n",
            "Epoch 642/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3046 - acc: 0.9207 - val_loss: 0.2973 - val_acc: 0.9247\n",
            "Epoch 643/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3044 - acc: 0.9209 - val_loss: 0.2972 - val_acc: 0.9240\n",
            "Epoch 644/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3043 - acc: 0.9208 - val_loss: 0.2970 - val_acc: 0.9245\n",
            "Epoch 645/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3040 - acc: 0.9210 - val_loss: 0.2968 - val_acc: 0.9240\n",
            "Epoch 646/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3040 - acc: 0.9209 - val_loss: 0.2967 - val_acc: 0.9242\n",
            "Epoch 647/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3038 - acc: 0.9208 - val_loss: 0.2967 - val_acc: 0.9248\n",
            "Epoch 648/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3036 - acc: 0.9209 - val_loss: 0.2966 - val_acc: 0.9248\n",
            "Epoch 649/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3034 - acc: 0.9210 - val_loss: 0.2966 - val_acc: 0.9245\n",
            "Epoch 650/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3035 - acc: 0.9209 - val_loss: 0.2962 - val_acc: 0.9252\n",
            "Epoch 651/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3031 - acc: 0.9210 - val_loss: 0.2963 - val_acc: 0.9240\n",
            "Epoch 652/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3031 - acc: 0.9210 - val_loss: 0.2961 - val_acc: 0.9247\n",
            "Epoch 653/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3027 - acc: 0.9211 - val_loss: 0.2961 - val_acc: 0.9247\n",
            "Epoch 654/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3027 - acc: 0.9210 - val_loss: 0.2960 - val_acc: 0.9245\n",
            "Epoch 655/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3025 - acc: 0.9213 - val_loss: 0.2961 - val_acc: 0.9250\n",
            "Epoch 656/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3022 - acc: 0.9211 - val_loss: 0.2957 - val_acc: 0.9242\n",
            "Epoch 657/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3022 - acc: 0.9213 - val_loss: 0.2959 - val_acc: 0.9248\n",
            "Epoch 658/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3022 - acc: 0.9213 - val_loss: 0.2958 - val_acc: 0.9245\n",
            "Epoch 659/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.3020 - acc: 0.9211 - val_loss: 0.2954 - val_acc: 0.9250\n",
            "Epoch 660/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3017 - acc: 0.9212 - val_loss: 0.2954 - val_acc: 0.9252\n",
            "Epoch 661/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3017 - acc: 0.9211 - val_loss: 0.2952 - val_acc: 0.9245\n",
            "Epoch 662/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3015 - acc: 0.9214 - val_loss: 0.2954 - val_acc: 0.9252\n",
            "Epoch 663/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3014 - acc: 0.9213 - val_loss: 0.2948 - val_acc: 0.9247\n",
            "Epoch 664/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3012 - acc: 0.9215 - val_loss: 0.2947 - val_acc: 0.9245\n",
            "Epoch 665/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3009 - acc: 0.9214 - val_loss: 0.2952 - val_acc: 0.9243\n",
            "Epoch 666/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3008 - acc: 0.9214 - val_loss: 0.2945 - val_acc: 0.9248\n",
            "Epoch 667/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3007 - acc: 0.9215 - val_loss: 0.2950 - val_acc: 0.9252\n",
            "Epoch 668/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3006 - acc: 0.9215 - val_loss: 0.2948 - val_acc: 0.9247\n",
            "Epoch 669/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3006 - acc: 0.9215 - val_loss: 0.2945 - val_acc: 0.9248\n",
            "Epoch 670/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3003 - acc: 0.9214 - val_loss: 0.2944 - val_acc: 0.9247\n",
            "Epoch 671/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3001 - acc: 0.9216 - val_loss: 0.2940 - val_acc: 0.9248\n",
            "Epoch 672/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2999 - acc: 0.9216 - val_loss: 0.2943 - val_acc: 0.9248\n",
            "Epoch 673/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.3000 - acc: 0.9217 - val_loss: 0.2940 - val_acc: 0.9250\n",
            "Epoch 674/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2997 - acc: 0.9216 - val_loss: 0.2942 - val_acc: 0.9250\n",
            "Epoch 675/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2995 - acc: 0.9217 - val_loss: 0.2941 - val_acc: 0.9245\n",
            "Epoch 676/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2995 - acc: 0.9216 - val_loss: 0.2939 - val_acc: 0.9247\n",
            "Epoch 677/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2993 - acc: 0.9217 - val_loss: 0.2936 - val_acc: 0.9245\n",
            "Epoch 678/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2992 - acc: 0.9219 - val_loss: 0.2940 - val_acc: 0.9247\n",
            "Epoch 679/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2990 - acc: 0.9217 - val_loss: 0.2930 - val_acc: 0.9262\n",
            "Epoch 680/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2989 - acc: 0.9218 - val_loss: 0.2934 - val_acc: 0.9252\n",
            "Epoch 681/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2987 - acc: 0.9218 - val_loss: 0.2933 - val_acc: 0.9252\n",
            "Epoch 682/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2987 - acc: 0.9218 - val_loss: 0.2933 - val_acc: 0.9240\n",
            "Epoch 683/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2984 - acc: 0.9217 - val_loss: 0.2931 - val_acc: 0.9257\n",
            "Epoch 684/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2982 - acc: 0.9221 - val_loss: 0.2933 - val_acc: 0.9243\n",
            "Epoch 685/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2982 - acc: 0.9219 - val_loss: 0.2927 - val_acc: 0.9252\n",
            "Epoch 686/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2979 - acc: 0.9220 - val_loss: 0.2926 - val_acc: 0.9255\n",
            "Epoch 687/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2978 - acc: 0.9220 - val_loss: 0.2926 - val_acc: 0.9257\n",
            "Epoch 688/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2977 - acc: 0.9221 - val_loss: 0.2927 - val_acc: 0.9250\n",
            "Epoch 689/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2976 - acc: 0.9220 - val_loss: 0.2929 - val_acc: 0.9255\n",
            "Epoch 690/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2976 - acc: 0.9221 - val_loss: 0.2922 - val_acc: 0.9245\n",
            "Epoch 691/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2975 - acc: 0.9222 - val_loss: 0.2923 - val_acc: 0.9247\n",
            "Epoch 692/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2973 - acc: 0.9219 - val_loss: 0.2920 - val_acc: 0.9255\n",
            "Epoch 693/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2970 - acc: 0.9222 - val_loss: 0.2923 - val_acc: 0.9248\n",
            "Epoch 694/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2969 - acc: 0.9223 - val_loss: 0.2921 - val_acc: 0.9253\n",
            "Epoch 695/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2967 - acc: 0.9220 - val_loss: 0.2921 - val_acc: 0.9258\n",
            "Epoch 696/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2967 - acc: 0.9226 - val_loss: 0.2918 - val_acc: 0.9247\n",
            "Epoch 697/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2966 - acc: 0.9222 - val_loss: 0.2917 - val_acc: 0.9247\n",
            "Epoch 698/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2964 - acc: 0.9223 - val_loss: 0.2915 - val_acc: 0.9250\n",
            "Epoch 699/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2963 - acc: 0.9225 - val_loss: 0.2916 - val_acc: 0.9247\n",
            "Epoch 700/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2961 - acc: 0.9225 - val_loss: 0.2918 - val_acc: 0.9255\n",
            "Epoch 701/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2961 - acc: 0.9224 - val_loss: 0.2912 - val_acc: 0.9257\n",
            "Epoch 702/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2958 - acc: 0.9226 - val_loss: 0.2915 - val_acc: 0.9255\n",
            "Epoch 703/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2958 - acc: 0.9224 - val_loss: 0.2911 - val_acc: 0.9257\n",
            "Epoch 704/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2955 - acc: 0.9226 - val_loss: 0.2912 - val_acc: 0.9257\n",
            "Epoch 705/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2955 - acc: 0.9224 - val_loss: 0.2910 - val_acc: 0.9245\n",
            "Epoch 706/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2954 - acc: 0.9225 - val_loss: 0.2909 - val_acc: 0.9247\n",
            "Epoch 707/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2951 - acc: 0.9226 - val_loss: 0.2912 - val_acc: 0.9253\n",
            "Epoch 708/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2951 - acc: 0.9226 - val_loss: 0.2907 - val_acc: 0.9248\n",
            "Epoch 709/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2948 - acc: 0.9225 - val_loss: 0.2906 - val_acc: 0.9260\n",
            "Epoch 710/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2949 - acc: 0.9226 - val_loss: 0.2905 - val_acc: 0.9255\n",
            "Epoch 711/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2946 - acc: 0.9227 - val_loss: 0.2904 - val_acc: 0.9250\n",
            "Epoch 712/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2945 - acc: 0.9225 - val_loss: 0.2904 - val_acc: 0.9262\n",
            "Epoch 713/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2944 - acc: 0.9226 - val_loss: 0.2902 - val_acc: 0.9248\n",
            "Epoch 714/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2944 - acc: 0.9227 - val_loss: 0.2901 - val_acc: 0.9243\n",
            "Epoch 715/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2941 - acc: 0.9229 - val_loss: 0.2899 - val_acc: 0.9248\n",
            "Epoch 716/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2940 - acc: 0.9229 - val_loss: 0.2900 - val_acc: 0.9255\n",
            "Epoch 717/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2940 - acc: 0.9226 - val_loss: 0.2901 - val_acc: 0.9255\n",
            "Epoch 718/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2936 - acc: 0.9230 - val_loss: 0.2897 - val_acc: 0.9250\n",
            "Epoch 719/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2936 - acc: 0.9229 - val_loss: 0.2897 - val_acc: 0.9253\n",
            "Epoch 720/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2934 - acc: 0.9229 - val_loss: 0.2894 - val_acc: 0.9255\n",
            "Epoch 721/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2935 - acc: 0.9229 - val_loss: 0.2898 - val_acc: 0.9248\n",
            "Epoch 722/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2934 - acc: 0.9230 - val_loss: 0.2898 - val_acc: 0.9250\n",
            "Epoch 723/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2932 - acc: 0.9231 - val_loss: 0.2894 - val_acc: 0.9252\n",
            "Epoch 724/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2930 - acc: 0.9231 - val_loss: 0.2890 - val_acc: 0.9252\n",
            "Epoch 725/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2929 - acc: 0.9231 - val_loss: 0.2892 - val_acc: 0.9260\n",
            "Epoch 726/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2928 - acc: 0.9230 - val_loss: 0.2889 - val_acc: 0.9253\n",
            "Epoch 727/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2926 - acc: 0.9231 - val_loss: 0.2891 - val_acc: 0.9247\n",
            "Epoch 728/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2924 - acc: 0.9232 - val_loss: 0.2888 - val_acc: 0.9252\n",
            "Epoch 729/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2923 - acc: 0.9232 - val_loss: 0.2886 - val_acc: 0.9255\n",
            "Epoch 730/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2921 - acc: 0.9232 - val_loss: 0.2889 - val_acc: 0.9250\n",
            "Epoch 731/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2921 - acc: 0.9232 - val_loss: 0.2886 - val_acc: 0.9252\n",
            "Epoch 732/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2919 - acc: 0.9233 - val_loss: 0.2886 - val_acc: 0.9253\n",
            "Epoch 733/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2918 - acc: 0.9234 - val_loss: 0.2884 - val_acc: 0.9255\n",
            "Epoch 734/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2917 - acc: 0.9233 - val_loss: 0.2882 - val_acc: 0.9248\n",
            "Epoch 735/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2917 - acc: 0.9233 - val_loss: 0.2885 - val_acc: 0.9255\n",
            "Epoch 736/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2915 - acc: 0.9233 - val_loss: 0.2886 - val_acc: 0.9252\n",
            "Epoch 737/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2914 - acc: 0.9234 - val_loss: 0.2882 - val_acc: 0.9252\n",
            "Epoch 738/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2911 - acc: 0.9234 - val_loss: 0.2884 - val_acc: 0.9257\n",
            "Epoch 739/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2910 - acc: 0.9234 - val_loss: 0.2877 - val_acc: 0.9255\n",
            "Epoch 740/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2908 - acc: 0.9235 - val_loss: 0.2881 - val_acc: 0.9257\n",
            "Epoch 741/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2909 - acc: 0.9234 - val_loss: 0.2879 - val_acc: 0.9255\n",
            "Epoch 742/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2908 - acc: 0.9234 - val_loss: 0.2878 - val_acc: 0.9252\n",
            "Epoch 743/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2905 - acc: 0.9235 - val_loss: 0.2882 - val_acc: 0.9255\n",
            "Epoch 744/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2906 - acc: 0.9235 - val_loss: 0.2876 - val_acc: 0.9260\n",
            "Epoch 745/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2903 - acc: 0.9236 - val_loss: 0.2877 - val_acc: 0.9255\n",
            "Epoch 746/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2901 - acc: 0.9236 - val_loss: 0.2875 - val_acc: 0.9260\n",
            "Epoch 747/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2901 - acc: 0.9235 - val_loss: 0.2876 - val_acc: 0.9253\n",
            "Epoch 748/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2899 - acc: 0.9238 - val_loss: 0.2879 - val_acc: 0.9255\n",
            "Epoch 749/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2898 - acc: 0.9237 - val_loss: 0.2876 - val_acc: 0.9257\n",
            "Epoch 750/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2897 - acc: 0.9239 - val_loss: 0.2876 - val_acc: 0.9253\n",
            "Epoch 751/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2897 - acc: 0.9238 - val_loss: 0.2869 - val_acc: 0.9250\n",
            "Epoch 752/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2894 - acc: 0.9239 - val_loss: 0.2872 - val_acc: 0.9252\n",
            "Epoch 753/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2893 - acc: 0.9239 - val_loss: 0.2869 - val_acc: 0.9257\n",
            "Epoch 754/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2892 - acc: 0.9238 - val_loss: 0.2872 - val_acc: 0.9250\n",
            "Epoch 755/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2891 - acc: 0.9238 - val_loss: 0.2867 - val_acc: 0.9260\n",
            "Epoch 756/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2889 - acc: 0.9239 - val_loss: 0.2868 - val_acc: 0.9262\n",
            "Epoch 757/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2890 - acc: 0.9241 - val_loss: 0.2868 - val_acc: 0.9253\n",
            "Epoch 758/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2889 - acc: 0.9239 - val_loss: 0.2867 - val_acc: 0.9252\n",
            "Epoch 759/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2888 - acc: 0.9239 - val_loss: 0.2865 - val_acc: 0.9253\n",
            "Epoch 760/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2884 - acc: 0.9241 - val_loss: 0.2865 - val_acc: 0.9250\n",
            "Epoch 761/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2884 - acc: 0.9240 - val_loss: 0.2867 - val_acc: 0.9253\n",
            "Epoch 762/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2882 - acc: 0.9241 - val_loss: 0.2862 - val_acc: 0.9257\n",
            "Epoch 763/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2880 - acc: 0.9239 - val_loss: 0.2863 - val_acc: 0.9253\n",
            "Epoch 764/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2880 - acc: 0.9241 - val_loss: 0.2862 - val_acc: 0.9257\n",
            "Epoch 765/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2878 - acc: 0.9242 - val_loss: 0.2862 - val_acc: 0.9252\n",
            "Epoch 766/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2877 - acc: 0.9242 - val_loss: 0.2861 - val_acc: 0.9253\n",
            "Epoch 767/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2879 - acc: 0.9241 - val_loss: 0.2863 - val_acc: 0.9253\n",
            "Epoch 768/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2875 - acc: 0.9242 - val_loss: 0.2867 - val_acc: 0.9255\n",
            "Epoch 769/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2875 - acc: 0.9243 - val_loss: 0.2859 - val_acc: 0.9262\n",
            "Epoch 770/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2873 - acc: 0.9244 - val_loss: 0.2859 - val_acc: 0.9255\n",
            "Epoch 771/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2872 - acc: 0.9244 - val_loss: 0.2859 - val_acc: 0.9257\n",
            "Epoch 772/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2870 - acc: 0.9242 - val_loss: 0.2854 - val_acc: 0.9263\n",
            "Epoch 773/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2868 - acc: 0.9244 - val_loss: 0.2855 - val_acc: 0.9262\n",
            "Epoch 774/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2868 - acc: 0.9243 - val_loss: 0.2855 - val_acc: 0.9265\n",
            "Epoch 775/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2868 - acc: 0.9242 - val_loss: 0.2855 - val_acc: 0.9252\n",
            "Epoch 776/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2866 - acc: 0.9244 - val_loss: 0.2853 - val_acc: 0.9267\n",
            "Epoch 777/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2865 - acc: 0.9243 - val_loss: 0.2854 - val_acc: 0.9260\n",
            "Epoch 778/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2863 - acc: 0.9245 - val_loss: 0.2855 - val_acc: 0.9258\n",
            "Epoch 779/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2862 - acc: 0.9244 - val_loss: 0.2851 - val_acc: 0.9265\n",
            "Epoch 780/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2861 - acc: 0.9246 - val_loss: 0.2849 - val_acc: 0.9260\n",
            "Epoch 781/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2860 - acc: 0.9244 - val_loss: 0.2849 - val_acc: 0.9262\n",
            "Epoch 782/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2861 - acc: 0.9243 - val_loss: 0.2846 - val_acc: 0.9260\n",
            "Epoch 783/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2858 - acc: 0.9245 - val_loss: 0.2853 - val_acc: 0.9262\n",
            "Epoch 784/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2857 - acc: 0.9244 - val_loss: 0.2848 - val_acc: 0.9262\n",
            "Epoch 785/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2855 - acc: 0.9246 - val_loss: 0.2849 - val_acc: 0.9260\n",
            "Epoch 786/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2854 - acc: 0.9246 - val_loss: 0.2845 - val_acc: 0.9258\n",
            "Epoch 787/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2853 - acc: 0.9247 - val_loss: 0.2843 - val_acc: 0.9263\n",
            "Epoch 788/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2852 - acc: 0.9247 - val_loss: 0.2843 - val_acc: 0.9262\n",
            "Epoch 789/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2851 - acc: 0.9246 - val_loss: 0.2844 - val_acc: 0.9263\n",
            "Epoch 790/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2849 - acc: 0.9246 - val_loss: 0.2842 - val_acc: 0.9268\n",
            "Epoch 791/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2848 - acc: 0.9247 - val_loss: 0.2842 - val_acc: 0.9262\n",
            "Epoch 792/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2847 - acc: 0.9248 - val_loss: 0.2839 - val_acc: 0.9258\n",
            "Epoch 793/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2846 - acc: 0.9246 - val_loss: 0.2840 - val_acc: 0.9260\n",
            "Epoch 794/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2846 - acc: 0.9246 - val_loss: 0.2837 - val_acc: 0.9268\n",
            "Epoch 795/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2845 - acc: 0.9247 - val_loss: 0.2838 - val_acc: 0.9262\n",
            "Epoch 796/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2843 - acc: 0.9249 - val_loss: 0.2839 - val_acc: 0.9267\n",
            "Epoch 797/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2842 - acc: 0.9250 - val_loss: 0.2838 - val_acc: 0.9263\n",
            "Epoch 798/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2839 - acc: 0.9249 - val_loss: 0.2839 - val_acc: 0.9265\n",
            "Epoch 799/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2840 - acc: 0.9249 - val_loss: 0.2834 - val_acc: 0.9267\n",
            "Epoch 800/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2838 - acc: 0.9249 - val_loss: 0.2834 - val_acc: 0.9265\n",
            "Epoch 801/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2838 - acc: 0.9250 - val_loss: 0.2835 - val_acc: 0.9267\n",
            "Epoch 802/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2838 - acc: 0.9250 - val_loss: 0.2836 - val_acc: 0.9263\n",
            "Epoch 803/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2835 - acc: 0.9250 - val_loss: 0.2830 - val_acc: 0.9268\n",
            "Epoch 804/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2833 - acc: 0.9250 - val_loss: 0.2834 - val_acc: 0.9268\n",
            "Epoch 805/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2832 - acc: 0.9251 - val_loss: 0.2829 - val_acc: 0.9263\n",
            "Epoch 806/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2832 - acc: 0.9253 - val_loss: 0.2829 - val_acc: 0.9262\n",
            "Epoch 807/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2831 - acc: 0.9251 - val_loss: 0.2832 - val_acc: 0.9262\n",
            "Epoch 808/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2830 - acc: 0.9250 - val_loss: 0.2831 - val_acc: 0.9260\n",
            "Epoch 809/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2829 - acc: 0.9253 - val_loss: 0.2829 - val_acc: 0.9262\n",
            "Epoch 810/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2827 - acc: 0.9253 - val_loss: 0.2828 - val_acc: 0.9265\n",
            "Epoch 811/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2825 - acc: 0.9254 - val_loss: 0.2829 - val_acc: 0.9257\n",
            "Epoch 812/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2824 - acc: 0.9254 - val_loss: 0.2826 - val_acc: 0.9263\n",
            "Epoch 813/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2823 - acc: 0.9251 - val_loss: 0.2824 - val_acc: 0.9263\n",
            "Epoch 814/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2823 - acc: 0.9253 - val_loss: 0.2824 - val_acc: 0.9258\n",
            "Epoch 815/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2821 - acc: 0.9252 - val_loss: 0.2824 - val_acc: 0.9263\n",
            "Epoch 816/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2820 - acc: 0.9252 - val_loss: 0.2824 - val_acc: 0.9268\n",
            "Epoch 817/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2819 - acc: 0.9254 - val_loss: 0.2822 - val_acc: 0.9260\n",
            "Epoch 818/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2818 - acc: 0.9253 - val_loss: 0.2823 - val_acc: 0.9265\n",
            "Epoch 819/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2817 - acc: 0.9254 - val_loss: 0.2821 - val_acc: 0.9267\n",
            "Epoch 820/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2815 - acc: 0.9255 - val_loss: 0.2821 - val_acc: 0.9262\n",
            "Epoch 821/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2814 - acc: 0.9255 - val_loss: 0.2820 - val_acc: 0.9267\n",
            "Epoch 822/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2814 - acc: 0.9252 - val_loss: 0.2820 - val_acc: 0.9270\n",
            "Epoch 823/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2811 - acc: 0.9256 - val_loss: 0.2817 - val_acc: 0.9263\n",
            "Epoch 824/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2812 - acc: 0.9255 - val_loss: 0.2821 - val_acc: 0.9262\n",
            "Epoch 825/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2809 - acc: 0.9256 - val_loss: 0.2813 - val_acc: 0.9262\n",
            "Epoch 826/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2810 - acc: 0.9254 - val_loss: 0.2817 - val_acc: 0.9267\n",
            "Epoch 827/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2809 - acc: 0.9256 - val_loss: 0.2815 - val_acc: 0.9268\n",
            "Epoch 828/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2807 - acc: 0.9258 - val_loss: 0.2813 - val_acc: 0.9275\n",
            "Epoch 829/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2805 - acc: 0.9256 - val_loss: 0.2812 - val_acc: 0.9270\n",
            "Epoch 830/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2804 - acc: 0.9255 - val_loss: 0.2812 - val_acc: 0.9267\n",
            "Epoch 831/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2803 - acc: 0.9257 - val_loss: 0.2812 - val_acc: 0.9268\n",
            "Epoch 832/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2802 - acc: 0.9256 - val_loss: 0.2814 - val_acc: 0.9268\n",
            "Epoch 833/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2802 - acc: 0.9257 - val_loss: 0.2810 - val_acc: 0.9267\n",
            "Epoch 834/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2801 - acc: 0.9258 - val_loss: 0.2811 - val_acc: 0.9267\n",
            "Epoch 835/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2799 - acc: 0.9260 - val_loss: 0.2810 - val_acc: 0.9272\n",
            "Epoch 836/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2798 - acc: 0.9258 - val_loss: 0.2812 - val_acc: 0.9272\n",
            "Epoch 837/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2797 - acc: 0.9259 - val_loss: 0.2807 - val_acc: 0.9272\n",
            "Epoch 838/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2796 - acc: 0.9259 - val_loss: 0.2812 - val_acc: 0.9267\n",
            "Epoch 839/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2796 - acc: 0.9259 - val_loss: 0.2810 - val_acc: 0.9265\n",
            "Epoch 840/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2794 - acc: 0.9261 - val_loss: 0.2807 - val_acc: 0.9265\n",
            "Epoch 841/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2793 - acc: 0.9261 - val_loss: 0.2805 - val_acc: 0.9273\n",
            "Epoch 842/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2792 - acc: 0.9260 - val_loss: 0.2806 - val_acc: 0.9265\n",
            "Epoch 843/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2791 - acc: 0.9260 - val_loss: 0.2805 - val_acc: 0.9272\n",
            "Epoch 844/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2790 - acc: 0.9258 - val_loss: 0.2805 - val_acc: 0.9270\n",
            "Epoch 845/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2790 - acc: 0.9260 - val_loss: 0.2806 - val_acc: 0.9267\n",
            "Epoch 846/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2788 - acc: 0.9262 - val_loss: 0.2800 - val_acc: 0.9272\n",
            "Epoch 847/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2787 - acc: 0.9261 - val_loss: 0.2801 - val_acc: 0.9263\n",
            "Epoch 848/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2785 - acc: 0.9264 - val_loss: 0.2798 - val_acc: 0.9267\n",
            "Epoch 849/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2785 - acc: 0.9260 - val_loss: 0.2803 - val_acc: 0.9270\n",
            "Epoch 850/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2783 - acc: 0.9262 - val_loss: 0.2798 - val_acc: 0.9268\n",
            "Epoch 851/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2783 - acc: 0.9264 - val_loss: 0.2802 - val_acc: 0.9267\n",
            "Epoch 852/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2783 - acc: 0.9261 - val_loss: 0.2801 - val_acc: 0.9263\n",
            "Epoch 853/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2782 - acc: 0.9262 - val_loss: 0.2795 - val_acc: 0.9275\n",
            "Epoch 854/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2780 - acc: 0.9264 - val_loss: 0.2798 - val_acc: 0.9270\n",
            "Epoch 855/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2781 - acc: 0.9262 - val_loss: 0.2797 - val_acc: 0.9270\n",
            "Epoch 856/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2779 - acc: 0.9263 - val_loss: 0.2801 - val_acc: 0.9267\n",
            "Epoch 857/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2778 - acc: 0.9264 - val_loss: 0.2797 - val_acc: 0.9277\n",
            "Epoch 858/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2776 - acc: 0.9263 - val_loss: 0.2797 - val_acc: 0.9272\n",
            "Epoch 859/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2775 - acc: 0.9264 - val_loss: 0.2795 - val_acc: 0.9265\n",
            "Epoch 860/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2774 - acc: 0.9264 - val_loss: 0.2794 - val_acc: 0.9270\n",
            "Epoch 861/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2772 - acc: 0.9264 - val_loss: 0.2794 - val_acc: 0.9272\n",
            "Epoch 862/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2772 - acc: 0.9265 - val_loss: 0.2792 - val_acc: 0.9270\n",
            "Epoch 863/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2770 - acc: 0.9264 - val_loss: 0.2795 - val_acc: 0.9272\n",
            "Epoch 864/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2771 - acc: 0.9263 - val_loss: 0.2790 - val_acc: 0.9272\n",
            "Epoch 865/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2769 - acc: 0.9266 - val_loss: 0.2792 - val_acc: 0.9270\n",
            "Epoch 866/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2768 - acc: 0.9265 - val_loss: 0.2791 - val_acc: 0.9270\n",
            "Epoch 867/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2767 - acc: 0.9266 - val_loss: 0.2792 - val_acc: 0.9270\n",
            "Epoch 868/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2766 - acc: 0.9266 - val_loss: 0.2787 - val_acc: 0.9268\n",
            "Epoch 869/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2766 - acc: 0.9267 - val_loss: 0.2788 - val_acc: 0.9268\n",
            "Epoch 870/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2764 - acc: 0.9267 - val_loss: 0.2788 - val_acc: 0.9268\n",
            "Epoch 871/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2763 - acc: 0.9266 - val_loss: 0.2787 - val_acc: 0.9268\n",
            "Epoch 872/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2762 - acc: 0.9267 - val_loss: 0.2787 - val_acc: 0.9268\n",
            "Epoch 873/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2761 - acc: 0.9269 - val_loss: 0.2786 - val_acc: 0.9273\n",
            "Epoch 874/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2760 - acc: 0.9266 - val_loss: 0.2790 - val_acc: 0.9273\n",
            "Epoch 875/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2759 - acc: 0.9268 - val_loss: 0.2785 - val_acc: 0.9267\n",
            "Epoch 876/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2758 - acc: 0.9266 - val_loss: 0.2781 - val_acc: 0.9280\n",
            "Epoch 877/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2758 - acc: 0.9269 - val_loss: 0.2782 - val_acc: 0.9273\n",
            "Epoch 878/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2756 - acc: 0.9268 - val_loss: 0.2782 - val_acc: 0.9275\n",
            "Epoch 879/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2754 - acc: 0.9269 - val_loss: 0.2782 - val_acc: 0.9272\n",
            "Epoch 880/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2752 - acc: 0.9269 - val_loss: 0.2781 - val_acc: 0.9273\n",
            "Epoch 881/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2752 - acc: 0.9269 - val_loss: 0.2783 - val_acc: 0.9270\n",
            "Epoch 882/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2753 - acc: 0.9268 - val_loss: 0.2782 - val_acc: 0.9275\n",
            "Epoch 883/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2751 - acc: 0.9270 - val_loss: 0.2780 - val_acc: 0.9268\n",
            "Epoch 884/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2752 - acc: 0.9270 - val_loss: 0.2781 - val_acc: 0.9273\n",
            "Epoch 885/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2751 - acc: 0.9268 - val_loss: 0.2780 - val_acc: 0.9272\n",
            "Epoch 886/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2749 - acc: 0.9272 - val_loss: 0.2777 - val_acc: 0.9277\n",
            "Epoch 887/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2747 - acc: 0.9270 - val_loss: 0.2776 - val_acc: 0.9268\n",
            "Epoch 888/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2746 - acc: 0.9271 - val_loss: 0.2774 - val_acc: 0.9278\n",
            "Epoch 889/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2747 - acc: 0.9270 - val_loss: 0.2776 - val_acc: 0.9270\n",
            "Epoch 890/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2745 - acc: 0.9272 - val_loss: 0.2776 - val_acc: 0.9278\n",
            "Epoch 891/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2744 - acc: 0.9271 - val_loss: 0.2774 - val_acc: 0.9272\n",
            "Epoch 892/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2744 - acc: 0.9271 - val_loss: 0.2773 - val_acc: 0.9272\n",
            "Epoch 893/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2742 - acc: 0.9271 - val_loss: 0.2772 - val_acc: 0.9272\n",
            "Epoch 894/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2740 - acc: 0.9272 - val_loss: 0.2772 - val_acc: 0.9277\n",
            "Epoch 895/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2741 - acc: 0.9271 - val_loss: 0.2773 - val_acc: 0.9278\n",
            "Epoch 896/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2738 - acc: 0.9274 - val_loss: 0.2768 - val_acc: 0.9280\n",
            "Epoch 897/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2737 - acc: 0.9274 - val_loss: 0.2770 - val_acc: 0.9270\n",
            "Epoch 898/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2737 - acc: 0.9271 - val_loss: 0.2769 - val_acc: 0.9273\n",
            "Epoch 899/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2735 - acc: 0.9273 - val_loss: 0.2768 - val_acc: 0.9275\n",
            "Epoch 900/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2735 - acc: 0.9271 - val_loss: 0.2768 - val_acc: 0.9270\n",
            "Epoch 901/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2734 - acc: 0.9274 - val_loss: 0.2769 - val_acc: 0.9270\n",
            "Epoch 902/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2733 - acc: 0.9274 - val_loss: 0.2767 - val_acc: 0.9270\n",
            "Epoch 903/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2732 - acc: 0.9275 - val_loss: 0.2766 - val_acc: 0.9273\n",
            "Epoch 904/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2732 - acc: 0.9274 - val_loss: 0.2769 - val_acc: 0.9273\n",
            "Epoch 905/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2730 - acc: 0.9276 - val_loss: 0.2766 - val_acc: 0.9268\n",
            "Epoch 906/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2731 - acc: 0.9274 - val_loss: 0.2765 - val_acc: 0.9267\n",
            "Epoch 907/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2728 - acc: 0.9273 - val_loss: 0.2768 - val_acc: 0.9268\n",
            "Epoch 908/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2727 - acc: 0.9278 - val_loss: 0.2762 - val_acc: 0.9275\n",
            "Epoch 909/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2727 - acc: 0.9274 - val_loss: 0.2765 - val_acc: 0.9275\n",
            "Epoch 910/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2726 - acc: 0.9275 - val_loss: 0.2760 - val_acc: 0.9273\n",
            "Epoch 911/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2724 - acc: 0.9275 - val_loss: 0.2764 - val_acc: 0.9277\n",
            "Epoch 912/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2724 - acc: 0.9277 - val_loss: 0.2761 - val_acc: 0.9272\n",
            "Epoch 913/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2723 - acc: 0.9277 - val_loss: 0.2763 - val_acc: 0.9275\n",
            "Epoch 914/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2722 - acc: 0.9276 - val_loss: 0.2755 - val_acc: 0.9278\n",
            "Epoch 915/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2722 - acc: 0.9276 - val_loss: 0.2758 - val_acc: 0.9270\n",
            "Epoch 916/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2721 - acc: 0.9277 - val_loss: 0.2759 - val_acc: 0.9275\n",
            "Epoch 917/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2719 - acc: 0.9276 - val_loss: 0.2759 - val_acc: 0.9273\n",
            "Epoch 918/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2719 - acc: 0.9277 - val_loss: 0.2758 - val_acc: 0.9272\n",
            "Epoch 919/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2718 - acc: 0.9277 - val_loss: 0.2759 - val_acc: 0.9268\n",
            "Epoch 920/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2717 - acc: 0.9278 - val_loss: 0.2754 - val_acc: 0.9277\n",
            "Epoch 921/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2716 - acc: 0.9276 - val_loss: 0.2758 - val_acc: 0.9272\n",
            "Epoch 922/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2716 - acc: 0.9278 - val_loss: 0.2756 - val_acc: 0.9275\n",
            "Epoch 923/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2714 - acc: 0.9276 - val_loss: 0.2753 - val_acc: 0.9270\n",
            "Epoch 924/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2713 - acc: 0.9277 - val_loss: 0.2755 - val_acc: 0.9275\n",
            "Epoch 925/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2713 - acc: 0.9276 - val_loss: 0.2755 - val_acc: 0.9268\n",
            "Epoch 926/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2712 - acc: 0.9276 - val_loss: 0.2754 - val_acc: 0.9275\n",
            "Epoch 927/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2712 - acc: 0.9280 - val_loss: 0.2753 - val_acc: 0.9275\n",
            "Epoch 928/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2709 - acc: 0.9278 - val_loss: 0.2752 - val_acc: 0.9277\n",
            "Epoch 929/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2709 - acc: 0.9277 - val_loss: 0.2750 - val_acc: 0.9272\n",
            "Epoch 930/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2708 - acc: 0.9278 - val_loss: 0.2751 - val_acc: 0.9270\n",
            "Epoch 931/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2707 - acc: 0.9279 - val_loss: 0.2752 - val_acc: 0.9265\n",
            "Epoch 932/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2706 - acc: 0.9279 - val_loss: 0.2749 - val_acc: 0.9275\n",
            "Epoch 933/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2705 - acc: 0.9280 - val_loss: 0.2748 - val_acc: 0.9273\n",
            "Epoch 934/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2705 - acc: 0.9279 - val_loss: 0.2749 - val_acc: 0.9272\n",
            "Epoch 935/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2703 - acc: 0.9280 - val_loss: 0.2749 - val_acc: 0.9275\n",
            "Epoch 936/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2702 - acc: 0.9281 - val_loss: 0.2745 - val_acc: 0.9270\n",
            "Epoch 937/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2701 - acc: 0.9280 - val_loss: 0.2747 - val_acc: 0.9268\n",
            "Epoch 938/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2701 - acc: 0.9279 - val_loss: 0.2749 - val_acc: 0.9277\n",
            "Epoch 939/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2700 - acc: 0.9279 - val_loss: 0.2746 - val_acc: 0.9267\n",
            "Epoch 940/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2700 - acc: 0.9281 - val_loss: 0.2746 - val_acc: 0.9275\n",
            "Epoch 941/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2699 - acc: 0.9280 - val_loss: 0.2744 - val_acc: 0.9270\n",
            "Epoch 942/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2696 - acc: 0.9282 - val_loss: 0.2743 - val_acc: 0.9270\n",
            "Epoch 943/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2696 - acc: 0.9280 - val_loss: 0.2742 - val_acc: 0.9268\n",
            "Epoch 944/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2697 - acc: 0.9279 - val_loss: 0.2745 - val_acc: 0.9270\n",
            "Epoch 945/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2695 - acc: 0.9281 - val_loss: 0.2746 - val_acc: 0.9268\n",
            "Epoch 946/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2696 - acc: 0.9279 - val_loss: 0.2742 - val_acc: 0.9270\n",
            "Epoch 947/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2694 - acc: 0.9279 - val_loss: 0.2742 - val_acc: 0.9268\n",
            "Epoch 948/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2692 - acc: 0.9283 - val_loss: 0.2743 - val_acc: 0.9263\n",
            "Epoch 949/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2691 - acc: 0.9282 - val_loss: 0.2740 - val_acc: 0.9265\n",
            "Epoch 950/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2691 - acc: 0.9280 - val_loss: 0.2739 - val_acc: 0.9273\n",
            "Epoch 951/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2690 - acc: 0.9280 - val_loss: 0.2740 - val_acc: 0.9272\n",
            "Epoch 952/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2689 - acc: 0.9280 - val_loss: 0.2736 - val_acc: 0.9268\n",
            "Epoch 953/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2689 - acc: 0.9281 - val_loss: 0.2739 - val_acc: 0.9273\n",
            "Epoch 954/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2689 - acc: 0.9283 - val_loss: 0.2735 - val_acc: 0.9272\n",
            "Epoch 955/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2688 - acc: 0.9280 - val_loss: 0.2737 - val_acc: 0.9270\n",
            "Epoch 956/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2687 - acc: 0.9280 - val_loss: 0.2737 - val_acc: 0.9270\n",
            "Epoch 957/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2685 - acc: 0.9282 - val_loss: 0.2738 - val_acc: 0.9263\n",
            "Epoch 958/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2685 - acc: 0.9285 - val_loss: 0.2735 - val_acc: 0.9272\n",
            "Epoch 959/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2684 - acc: 0.9283 - val_loss: 0.2732 - val_acc: 0.9268\n",
            "Epoch 960/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2683 - acc: 0.9283 - val_loss: 0.2735 - val_acc: 0.9273\n",
            "Epoch 961/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2682 - acc: 0.9284 - val_loss: 0.2734 - val_acc: 0.9268\n",
            "Epoch 962/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2683 - acc: 0.9283 - val_loss: 0.2731 - val_acc: 0.9273\n",
            "Epoch 963/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2681 - acc: 0.9282 - val_loss: 0.2734 - val_acc: 0.9263\n",
            "Epoch 964/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2679 - acc: 0.9284 - val_loss: 0.2731 - val_acc: 0.9273\n",
            "Epoch 965/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2679 - acc: 0.9284 - val_loss: 0.2734 - val_acc: 0.9267\n",
            "Epoch 966/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2679 - acc: 0.9284 - val_loss: 0.2732 - val_acc: 0.9268\n",
            "Epoch 967/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2677 - acc: 0.9286 - val_loss: 0.2729 - val_acc: 0.9270\n",
            "Epoch 968/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2677 - acc: 0.9284 - val_loss: 0.2728 - val_acc: 0.9272\n",
            "Epoch 969/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2677 - acc: 0.9285 - val_loss: 0.2732 - val_acc: 0.9273\n",
            "Epoch 970/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2675 - acc: 0.9284 - val_loss: 0.2731 - val_acc: 0.9272\n",
            "Epoch 971/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2674 - acc: 0.9286 - val_loss: 0.2728 - val_acc: 0.9275\n",
            "Epoch 972/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2675 - acc: 0.9286 - val_loss: 0.2726 - val_acc: 0.9268\n",
            "Epoch 973/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2674 - acc: 0.9285 - val_loss: 0.2723 - val_acc: 0.9273\n",
            "Epoch 974/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2672 - acc: 0.9286 - val_loss: 0.2726 - val_acc: 0.9267\n",
            "Epoch 975/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2671 - acc: 0.9284 - val_loss: 0.2726 - val_acc: 0.9275\n",
            "Epoch 976/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2670 - acc: 0.9285 - val_loss: 0.2726 - val_acc: 0.9270\n",
            "Epoch 977/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2669 - acc: 0.9286 - val_loss: 0.2728 - val_acc: 0.9272\n",
            "Epoch 978/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2669 - acc: 0.9286 - val_loss: 0.2724 - val_acc: 0.9272\n",
            "Epoch 979/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2668 - acc: 0.9287 - val_loss: 0.2723 - val_acc: 0.9272\n",
            "Epoch 980/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2667 - acc: 0.9285 - val_loss: 0.2723 - val_acc: 0.9267\n",
            "Epoch 981/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2667 - acc: 0.9285 - val_loss: 0.2722 - val_acc: 0.9268\n",
            "Epoch 982/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2666 - acc: 0.9286 - val_loss: 0.2723 - val_acc: 0.9267\n",
            "Epoch 983/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2665 - acc: 0.9286 - val_loss: 0.2721 - val_acc: 0.9267\n",
            "Epoch 984/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2663 - acc: 0.9287 - val_loss: 0.2721 - val_acc: 0.9263\n",
            "Epoch 985/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2664 - acc: 0.9286 - val_loss: 0.2719 - val_acc: 0.9272\n",
            "Epoch 986/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2662 - acc: 0.9288 - val_loss: 0.2719 - val_acc: 0.9275\n",
            "Epoch 987/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2661 - acc: 0.9288 - val_loss: 0.2720 - val_acc: 0.9272\n",
            "Epoch 988/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2661 - acc: 0.9289 - val_loss: 0.2720 - val_acc: 0.9270\n",
            "Epoch 989/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2662 - acc: 0.9286 - val_loss: 0.2718 - val_acc: 0.9273\n",
            "Epoch 990/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2661 - acc: 0.9288 - val_loss: 0.2718 - val_acc: 0.9273\n",
            "Epoch 991/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2660 - acc: 0.9287 - val_loss: 0.2716 - val_acc: 0.9275\n",
            "Epoch 992/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2659 - acc: 0.9286 - val_loss: 0.2715 - val_acc: 0.9258\n",
            "Epoch 993/1000\n",
            "54000/54000 [==============================] - 1s 10us/step - loss: 0.2658 - acc: 0.9288 - val_loss: 0.2713 - val_acc: 0.9267\n",
            "Epoch 994/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2656 - acc: 0.9289 - val_loss: 0.2715 - val_acc: 0.9272\n",
            "Epoch 995/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2657 - acc: 0.9288 - val_loss: 0.2716 - val_acc: 0.9272\n",
            "Epoch 996/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2656 - acc: 0.9288 - val_loss: 0.2711 - val_acc: 0.9270\n",
            "Epoch 997/1000\n",
            "54000/54000 [==============================] - 1s 9us/step - loss: 0.2653 - acc: 0.9290 - val_loss: 0.2713 - val_acc: 0.9270\n",
            "Epoch 998/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2653 - acc: 0.9290 - val_loss: 0.2712 - val_acc: 0.9275\n",
            "Epoch 999/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2653 - acc: 0.9288 - val_loss: 0.2714 - val_acc: 0.9270\n",
            "Epoch 1000/1000\n",
            "54000/54000 [==============================] - 0s 9us/step - loss: 0.2652 - acc: 0.9291 - val_loss: 0.2711 - val_acc: 0.9272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "arNvXRj8W3i9",
        "outputId": "8702f5f1-c9ad-4b87-c4e8-30d6ba132a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot the progression of the training process\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AY46AfbHT0SZ",
        "outputId": "9c327125-2d67-4f04-fd0e-affb74826fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "# Evaluate model on test data - how often does the network predict the right label after training?\n",
        "\n",
        "loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
        "\n",
        "print(f'Test loss: {loss:.3}')\n",
        "print(f'Test accuracy: {accuracy:.3}')\n",
        "\n",
        "# Make a confusion matrix to see which numbers are difficult to disentangle\n",
        "\n",
        "y_pred_test = model.predict_proba(x_test) # obtain one-hot encoded predictions for the x_test images\n",
        "y_test_index      = [ np.argmax(i) for i in y_test ] # actual number known labels\n",
        "y_pred_test_index = [ np.argmax(i) for i in y_pred_test ] # actual number predictions\n",
        "y_pred_test_proba = [ y_pred_test[i][ y_pred_test_index[i] ] for i in range(len(y_test_index)) ] # probabilities to be correct\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.title('Confusion matrix', fontsize=16)\n",
        "plt.imshow(confusion_matrix(y_test_index, y_pred_test_index ))\n",
        "plt.xticks(np.arange(10), np.arange(10), rotation=0, fontsize=12)\n",
        "plt.yticks(np.arange(10), np.arange(10), fontsize=12)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "### STUDENT CODE HERE ###\n",
        "### --> Now predict again the labels for the test images, but after proper training.\n",
        "###  Build a confusion matrix to show which labels we often confuse with what.\n",
        "###  (Note that the y_test and y_pred are still one-hot encoded, so you need to get\n",
        "###   the index of the maximum entry to find the corresponding predicted 'number'.\n",
        "### END STUDENT CODE ###"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.313\n",
            "Test accuracy: 0.91\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAFsCAYAAAAe+sRkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVk2TjJmZpbN/weSf0QsecFBdgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e824_G2qZ4Lg",
        "outputId": "da05aaaf-25a7-43a9-d246-d3127844d029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Show some predicted labels and their probabilities to be correct\n",
        "\n",
        "### STUDENT CODE HERE ###\n",
        "plt.figure(figsize=[16,16])\n",
        "for i in range(10):\n",
        "    plt.subplot(1,10,i+1)\n",
        "    plt.title(\"Label: {0}\\nPrediction:{1}\\nProba:{2:.3f}\".format(\n",
        "        y_test_index[i], y_pred_test_index[i], y_pred_test_proba[i] ))\n",
        "    plt.imshow(x_test[i].reshape([28,28]),cmap='gray');\n",
        "### --> Now show some hand-written digit images from the test sample, \n",
        "###  their corresponding true label, their predicted label from your network,\n",
        "###  and the probability associated with that prediction.\n",
        "### END STUDENT CODE ###"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA54AAACZCAYAAABHYuXCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1152x1152 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C3GO3lDpR4qm",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}